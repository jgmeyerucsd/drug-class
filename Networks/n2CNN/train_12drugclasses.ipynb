{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs breeds\n",
    "\n",
    "https://youtu.be/JNxcznsrRb8?t=1h31m8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "??ConvLearner.pretrained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/drugs/pics/\"\n",
    "sz = 224\n",
    "arch = resnext101_64\n",
    "bs = 128\n",
    "label_csv = f'{PATH}labels.csv'\n",
    "n = len(list(open(label_csv))) - 1 # header is not counted (-1)\n",
    "val_idxs = get_cv_idxs(n, seed=random.sample(range(9), 1)) # random 20% data for validation set, different each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs): # sz: image size, bs: batch size\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}labels.csv',\n",
    "                                       val_idxs=val_idxs, suffix='.png', tfms=tfms, bs=bs)\n",
    "    \n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/13\n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/37\n",
    "    return data if sz > 300 else data.resize(340, 'tmp') # Reading the jpgs and resizing is slow for big images, so resizing them all to 340 first saves time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_loop1(k, epochs):\n",
    "    validation_accuracy = []\n",
    "    for reps in range(k):\n",
    "        val_idxs = get_cv_idxs(n, seed=random.sample(range(1000), 1)) # random 20% data for validation set\n",
    "        data = get_data(sz, bs)\n",
    "        learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
    "        learn.fit(1e-2, epochs)\n",
    "        validation_accuracy.append(val_acc)\n",
    "        learn.save(str(reps)+'_12clsmodel_kfold.model')\n",
    "    return validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1f7299e3b94b42badca74b601e36fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7aa3175e6048aa87101d1de71fe2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.070548   1.669185   0.429075  \n",
      "    1      1.76888    1.556218   0.46652                  \n",
      "    2      1.645123   1.498228   0.482379                  \n",
      "    3      1.545225   1.455022   0.494273                  \n",
      "    4      1.480391   1.424      0.497357                 \n",
      "    5      1.422637   1.385548   0.511454                 \n",
      "    6      1.381897   1.341969   0.517181                 \n",
      "    7      1.324599   1.327606   0.532159                 \n",
      "    8      1.290708   1.325242   0.532159                 \n",
      "    9      1.267365   1.307441   0.54141                   \n",
      "    10     1.229282   1.292712   0.534361                  \n",
      "    11     1.208318   1.281906   0.547137                  \n",
      "    12     1.167715   1.278463   0.546696                 \n",
      "    13     1.14537    1.268767   0.548018                 \n",
      "    14     1.109101   1.2657     0.548018                 \n",
      "    15     1.101349   1.247311   0.562555                 \n",
      "    16     1.082755   1.267614   0.553744                 \n",
      "    17     1.063979   1.247473   0.559912                 \n",
      "    18     1.034137   1.240732   0.573128                 \n",
      "    19     1.034894   1.234701   0.554626                 \n",
      "    20     1.025751   1.244344   0.559912                 \n",
      "    21     0.997286   1.230501   0.572687                  \n",
      "    22     0.975862   1.228382   0.568282                  \n",
      "    23     0.965878   1.238517   0.555947                  \n",
      "    24     0.948999   1.229392   0.565198                  \n",
      "    25     0.93679    1.231834   0.570044                  \n",
      "    26     0.93418    1.248596   0.555066                  \n",
      "    27     0.913114   1.232479   0.56696                   \n",
      "    28     0.909396   1.233259   0.562115                  \n",
      "    29     0.896538   1.227418   0.574449                  \n",
      "    30     0.857907   1.217581   0.577533                  \n",
      "    31     0.861527   1.224589   0.56652                   \n",
      "    32     0.85462    1.237073   0.565639                  \n",
      "    33     0.840957   1.229171   0.565639                  \n",
      "    34     0.826524   1.214126   0.574009                  \n",
      "    35     0.826948   1.241328   0.577093                  \n",
      "    36     0.809648   1.236241   0.562996                  \n",
      "    37     0.791149   1.239395   0.573128                  \n",
      "    38     0.802589   1.249129   0.56652                   \n",
      "    39     0.782439   1.222229   0.578414                  \n",
      "    40     0.77204    1.235456   0.570925                  \n",
      "    41     0.780646   1.235673   0.572687                  \n",
      "    42     0.768195   1.248821   0.57533                   \n",
      "    43     0.759036   1.236744   0.57533                   \n",
      "    44     0.744036   1.236491   0.576652                  \n",
      "    45     0.73689    1.265776   0.578855                  \n",
      "    46     0.728577   1.242155   0.577093                  \n",
      "    47     0.709852   1.259064   0.571806                  \n",
      "    48     0.704631   1.24679    0.574009                  \n",
      "    49     0.702818   1.256391   0.574009                  \n",
      "    50     0.702037   1.272853   0.576211                  \n",
      "    51     0.687737   1.249614   0.575771                  \n",
      "    52     0.676178   1.258206   0.572247                  \n",
      "    53     0.68634    1.281474   0.573568                  \n",
      "    54     0.668184   1.276732   0.580617                  \n",
      "    55     0.685294   1.269072   0.585463                  \n",
      "    56     0.677062   1.268034   0.578414                  \n",
      "    57     0.671846   1.245691   0.58326                   \n",
      "    58     0.65749    1.267036   0.579736                  \n",
      "    59     0.654705   1.27405    0.577093                  \n",
      "    60     0.639779   1.284162   0.573568                  \n",
      "    61     0.636122   1.293149   0.57533                   \n",
      "    62     0.623986   1.294272   0.577974                  \n",
      "    63     0.622222   1.290746   0.577533                  \n",
      "    64     0.631609   1.280938   0.580176                  \n",
      "    65     0.606202   1.298517   0.57533                   \n",
      "    66     0.607577   1.301216   0.576652                  \n",
      "    67     0.608291   1.314219   0.581498                  \n",
      "    68     0.61089    1.297083   0.585903                  \n",
      "    69     0.611714   1.299743   0.586344                  \n",
      "    70     0.603989   1.292454   0.581057                  \n",
      "    71     0.596725   1.32695    0.574009                  \n",
      "    72     0.599184   1.330556   0.586344                  \n",
      "    73     0.602055   1.30428    0.584581                  \n",
      "    74     0.586397   1.317852   0.579736                  \n",
      "    75     0.573427   1.319958   0.577974                  \n",
      "    76     0.588207   1.316612   0.582819                  \n",
      "    77     0.581229   1.319798   0.588546                  \n",
      "    78     0.571777   1.342913   0.581498                  \n",
      "    79     0.568303   1.319494   0.581057                  \n",
      "    80     0.567248   1.329763   0.579736                  \n",
      "    81     0.565798   1.332212   0.581057                  \n",
      "    82     0.569499   1.323464   0.588546                  \n",
      "    83     0.562022   1.336884   0.586784                  \n",
      "    84     0.558586   1.348433   0.581498                  \n",
      "    85     0.553271   1.336645   0.587225                  \n",
      "    86     0.541567   1.312578   0.580176                  \n",
      "    87     0.545476   1.337063   0.585903                  \n",
      "    88     0.534421   1.333658   0.586784                  \n",
      "    89     0.537711   1.340964   0.582379                  \n",
      "    90     0.534839   1.348511   0.581938                  \n",
      "    91     0.517404   1.349101   0.588987                  \n",
      "    92     0.5294     1.337855   0.582819                  \n",
      "    93     0.529848   1.348112   0.579295                  \n",
      "    94     0.526318   1.344196   0.588106                  \n",
      "    95     0.508803   1.361369   0.586344                  \n",
      "    96     0.525605   1.361392   0.581938                  \n",
      "    97     0.52395    1.374073   0.587665                  \n",
      "    98     0.517148   1.367663   0.574449                  \n",
      "    99     0.508821   1.363858   0.581498                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98535abca6d047a1a9347eb231ec7f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043902367ce49fa9acfab98e3b8c19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.082087   1.680048   0.448018  \n",
      "    1      1.790978   1.573119   0.445815                 \n",
      "    2      1.633364   1.496212   0.478414                 \n",
      "    3      1.541974   1.448939   0.488987                 \n",
      "    4      1.492486   1.421354   0.502203                 \n",
      "    5      1.438499   1.395803   0.511894                 \n",
      "    6      1.383618   1.377353   0.508811                 \n",
      "    7      1.351633   1.365814   0.501762                 \n",
      "    8      1.306841   1.33187    0.528634                 \n",
      "    9      1.276673   1.331444   0.534361                 \n",
      "    10     1.234611   1.311445   0.534361                 \n",
      "    11     1.201428   1.3091     0.530396                 \n",
      "    12     1.181753   1.291834   0.539207                 \n",
      "    13     1.172887   1.275719   0.545815                 \n",
      "    14     1.148957   1.282912   0.546696                 \n",
      "    15     1.109257   1.271912   0.543172                 \n",
      "    16     1.099581   1.269104   0.551982                 \n",
      "    17     1.067157   1.266187   0.559031                 \n",
      "    18     1.060859   1.261197   0.557709                 \n",
      "    19     1.038969   1.234647   0.562996                 \n",
      "    20     1.021561   1.238359   0.557709                 \n",
      "    21     1.010328   1.243594   0.554626                  \n",
      "    22     0.992421   1.240141   0.562115                  \n",
      "    23     0.972052   1.237733   0.555066                  \n",
      "    24     0.965946   1.236956   0.550661                  \n",
      "    25     0.94041    1.231184   0.553744                  \n",
      "    26     0.940847   1.225769   0.568282                  \n",
      "    27     0.934773   1.230642   0.566079                  \n",
      "    28     0.900665   1.264242   0.559031                  \n",
      "    29     0.898406   1.235651   0.564758                  \n",
      "    30     0.878996   1.237124   0.56652                   \n",
      "    31     0.872598   1.231957   0.563877                  \n",
      "    32     0.871906   1.229773   0.567401                  \n",
      "    33     0.86188    1.252807   0.554626                  \n",
      "    34     0.846314   1.245944   0.556388                  \n",
      "    35     0.830004   1.259591   0.559031                  \n",
      "    36     0.824792   1.217773   0.572687                  \n",
      "    37     0.804777   1.246344   0.565639                  \n",
      "    38     0.793097   1.249604   0.570044                  \n",
      "    39     0.779065   1.246571   0.568282                  \n",
      "    40     0.780615   1.24613    0.571366                  \n",
      "    41     0.767487   1.251246   0.573128                  \n",
      "    42     0.775359   1.251243   0.56696                   \n",
      "    43     0.768438   1.248403   0.56652                   \n",
      "    44     0.759263   1.255526   0.573128                  \n",
      "    45     0.735464   1.244421   0.572687                  \n",
      "    46     0.73502    1.242629   0.572687                  \n",
      "    47     0.729917   1.247973   0.570925                  \n",
      "    48     0.720608   1.255668   0.571366                  \n",
      "    49     0.717724   1.265483   0.565639                  \n",
      "    50     0.701853   1.271361   0.562115                  \n",
      "    51     0.698755   1.281674   0.565198                  \n",
      "    52     0.699338   1.266948   0.56652                   \n",
      "    53     0.696096   1.263962   0.562996                  \n",
      "    54     0.676007   1.267152   0.57489                   \n",
      "    55     0.674603   1.273301   0.570485                  \n",
      "    56     0.669297   1.292154   0.579295                  \n",
      "    57     0.66781    1.278089   0.571366                  \n",
      "    58     0.657483   1.265588   0.572247                  \n",
      "    59     0.640502   1.286131   0.572247                  \n",
      "    60     0.65851    1.273859   0.574009                  \n",
      "    61     0.654834   1.280584   0.574449                  \n",
      "    62     0.640052   1.291755   0.581057                  \n",
      "    63     0.634973   1.295771   0.578414                  \n",
      "    64     0.624108   1.278348   0.580617                  \n",
      "    65     0.628796   1.294121   0.574449                  \n",
      "    66     0.623765   1.298513   0.575771                  \n",
      "    67     0.625182   1.312995   0.581057                  \n",
      "    68     0.61409    1.30421    0.576211                  \n",
      "    69     0.610714   1.299369   0.574449                  \n",
      "    70     0.59732    1.303085   0.581498                  \n",
      "    71     0.592681   1.318062   0.571806                  \n",
      "    72     0.594813   1.311456   0.576211                  \n",
      "    73     0.593784   1.305031   0.577533                  \n",
      "    74     0.582318   1.311525   0.584581                  \n",
      "    75     0.577402   1.318194   0.580617                  \n",
      "    76     0.578964   1.31475    0.570485                  \n",
      "    77     0.569062   1.328922   0.57489                   \n",
      "    78     0.583728   1.323458   0.576652                  \n",
      "    79     0.566984   1.319646   0.572687                  \n",
      "    80     0.553818   1.330268   0.574449                  \n",
      "    81     0.561557   1.321542   0.582819                  \n",
      "    82     0.560519   1.313866   0.579736                  \n",
      "    83     0.555644   1.320708   0.578855                  \n",
      "    84     0.563933   1.330707   0.58326                   \n",
      "    85     0.562533   1.319714   0.579295                  \n",
      "    86     0.551492   1.326786   0.57533                   \n",
      "    87     0.542695   1.344191   0.570485                  \n",
      "    88     0.546974   1.353783   0.578414                  \n",
      "    89     0.548072   1.360694   0.579736                  \n",
      "    90     0.555586   1.348176   0.576652                  \n",
      "    91     0.54847    1.344415   0.576652                  \n",
      "    92     0.531599   1.372165   0.569163                  \n",
      "    93     0.521741   1.345386   0.579295                  \n",
      "    94     0.535891   1.352297   0.580617                  \n",
      "    95     0.525201   1.356886   0.581498                  \n",
      "    96     0.526208   1.353858   0.579736                  \n",
      "    97     0.524389   1.350399   0.576211                  \n",
      "    98     0.532762   1.345039   0.580617                  \n",
      "    99     0.535307   1.367706   0.577093                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe74efb0b064340934837b9f50f17a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fea627bd2fa4c41bdd1152e51d7d1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.075945   1.67589    0.43348   \n",
      "    1      1.768355   1.555436   0.463436                 \n",
      "    2      1.628673   1.482706   0.481938                 \n",
      "    3      1.542327   1.453784   0.486784                 \n",
      "    4      1.473394   1.400499   0.509692                 \n",
      "    5      1.419219   1.368242   0.51674                  \n",
      "    6      1.36255    1.365166   0.518502                 \n",
      "    7      1.318509   1.335945   0.533921                 \n",
      "    8      1.288755   1.330634   0.526432                 \n",
      "    9      1.255152   1.320169   0.530396                 \n",
      "    10     1.224379   1.296715   0.548018                 \n",
      "    11     1.200319   1.280242   0.557709                 \n",
      "    12     1.168186   1.265933   0.559912                 \n",
      "    13     1.145757   1.264515   0.555947                 \n",
      "    14     1.124273   1.275745   0.555066                 \n",
      "    15     1.101011   1.265241   0.549339                 \n",
      "    16     1.074317   1.266828   0.554185                 \n",
      "    17     1.062034   1.260732   0.551542                 \n",
      "    18     1.053987   1.242983   0.554626                 \n",
      "    19     1.030799   1.245646   0.563436                 \n",
      "    20     1.017224   1.249517   0.559471                  \n",
      "    21     0.996457   1.252782   0.559912                  \n",
      "    22     0.995468   1.243151   0.571366                  \n",
      "    23     0.973596   1.236776   0.567401                  \n",
      "    24     0.960767   1.216651   0.574449                  \n",
      "    25     0.948706   1.219184   0.56652                   \n",
      "    26     0.922333   1.239757   0.572687                  \n",
      "    27     0.905001   1.222907   0.568282                  \n",
      "    28     0.889068   1.238663   0.562555                  \n",
      "    29     0.894036   1.232819   0.571806                  \n",
      "    30     0.876454   1.225042   0.571806                  \n",
      "    31     0.870697   1.232423   0.56652                   \n",
      "    32     0.846949   1.230896   0.568722                  \n",
      "    33     0.851309   1.22774    0.570925                  \n",
      "    34     0.834051   1.239061   0.572687                  \n",
      "    35     0.819771   1.255322   0.579295                  \n",
      "    36     0.815389   1.229643   0.576211                  \n",
      "    37     0.81184    1.23873    0.575771                  \n",
      "    38     0.797088   1.238646   0.56652                   \n",
      "    39     0.779605   1.23664    0.570485                  \n",
      "    40     0.767446   1.248147   0.572687                  \n",
      "    41     0.76354    1.264133   0.570044                  \n",
      "    42     0.758566   1.252791   0.575771                  \n",
      "    43     0.743801   1.254786   0.570925                  \n",
      "    44     0.736743   1.244689   0.573128                  \n",
      "    45     0.737313   1.258209   0.580617                  \n",
      "    46     0.725815   1.260139   0.572687                  \n",
      "    47     0.716057   1.267855   0.584141                  \n",
      "    48     0.718051   1.270633   0.5837                    \n",
      "    49     0.703176   1.269347   0.578855                  \n",
      "    50     0.697806   1.261478   0.582819                  \n",
      "    51     0.679867   1.249103   0.588106                  \n",
      "    52     0.677528   1.263053   0.581498                  \n",
      "    53     0.67936    1.285932   0.579295                  \n",
      "    54     0.674636   1.271208   0.5837                    \n",
      "    55     0.660194   1.279263   0.581938                  \n",
      "    56     0.664846   1.285196   0.573568                  \n",
      "    57     0.666549   1.282417   0.569163                  \n",
      "    58     0.660277   1.290093   0.582379                  \n",
      "    59     0.653416   1.283684   0.576652                  \n",
      "    60     0.658145   1.285947   0.581938                  \n",
      "    61     0.635582   1.299329   0.582379                  \n",
      "    62     0.62691    1.292937   0.575771                  \n",
      "    63     0.623102   1.298447   0.581938                  \n",
      "    64     0.620303   1.311918   0.57533                   \n",
      "    65     0.617619   1.31322    0.579736                  \n",
      "    66     0.594585   1.307389   0.573128                  \n",
      "    67     0.609709   1.314146   0.572247                  \n",
      "    68     0.616523   1.299848   0.577533                  \n",
      "    69     0.60861    1.313483   0.582819                  \n",
      "    70     0.592707   1.305174   0.584581                  \n",
      "    71     0.586753   1.314613   0.577093                  \n",
      "    72     0.580636   1.326354   0.582379                  \n",
      "    73     0.586453   1.30848    0.581498                  \n",
      "    74     0.595795   1.3275     0.580176                  \n",
      "    75     0.577933   1.316858   0.576652                  \n",
      "    76     0.585238   1.322986   0.584581                  \n",
      "    77     0.576615   1.324546   0.581057                  \n",
      "    78     0.573005   1.311983   0.579736                  \n",
      "    79     0.573813   1.327986   0.581498                  \n",
      "    80     0.567143   1.333149   0.581057                  \n",
      "    81     0.555832   1.321373   0.584141                  \n",
      "    82     0.54208    1.341774   0.577093                  \n",
      "    83     0.554719   1.35388    0.57533                   \n",
      "    84     0.554646   1.343735   0.580617                  \n",
      "    85     0.55436    1.333868   0.581057                  \n",
      "    86     0.542222   1.338862   0.581938                  \n",
      "    87     0.53701    1.343015   0.579736                  \n",
      "    88     0.543657   1.350021   0.577533                  \n",
      "    89     0.54259    1.357207   0.576652                  \n",
      "    90     0.545487   1.352239   0.581498                  \n",
      "    91     0.525728   1.341318   0.573128                  \n",
      "    92     0.53005    1.35571    0.579736                  \n",
      "    93     0.530803   1.358299   0.578855                  \n",
      "    94     0.523364   1.359931   0.578414                  \n",
      "    95     0.517208   1.347478   0.584141                  \n",
      "    96     0.517322   1.36986    0.578414                  \n",
      "    97     0.517853   1.35725    0.584141                  \n",
      "    98     0.513433   1.383332   0.584581                  \n",
      "    99     0.513121   1.368347   0.582379                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3041021ce8754895b22c477fc7fa0b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df51b298d18b48bcb654267e5512a7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.058092   1.682293   0.431278  \n",
      "    1      1.770803   1.590136   0.459912                 \n",
      "    2      1.63962    1.517988   0.467401                 \n",
      "    3      1.552602   1.463593   0.485022                 \n",
      "    4      1.480642   1.419397   0.503084                 \n",
      "    5      1.42187    1.393795   0.517621                 \n",
      "    6      1.366614   1.363929   0.514097                 \n",
      "    7      1.338306   1.355018   0.519824                 \n",
      "    8      1.29881    1.330372   0.52511                  \n",
      "    9      1.26282    1.338571   0.532159                 \n",
      "    10     1.23036    1.306958   0.53304                  \n",
      "    11     1.19982    1.294975   0.537445                 \n",
      "    12     1.182761   1.296886   0.546696                 \n",
      "    13     1.152609   1.266105   0.544493                 \n",
      "    14     1.128042   1.264656   0.550661                 \n",
      "    15     1.126551   1.258455   0.551542                 \n",
      "    16     1.095404   1.258473   0.550661                 \n",
      "    17     1.071569   1.255531   0.551982                 \n",
      "    18     1.055783   1.275347   0.554185                  \n",
      "    19     1.034462   1.265396   0.555947                 \n",
      "    20     1.015556   1.24226    0.555066                 \n",
      "    21     1.009003   1.238422   0.557709                  \n",
      "    22     0.996686   1.233629   0.564317                  \n",
      "    23     0.973592   1.228494   0.56696                   \n",
      "    24     0.971168   1.241822   0.560352                  \n",
      "    25     0.957282   1.238618   0.563877                  \n",
      "    26     0.938812   1.231183   0.557709                  \n",
      "    27     0.926318   1.221112   0.57533                   \n",
      "    28     0.906546   1.229854   0.56696                   \n",
      "    29     0.896056   1.227099   0.56652                   \n",
      "    30     0.87859    1.22947    0.57489                   \n",
      "    31     0.87204    1.224626   0.571366                  \n",
      "    32     0.860895   1.21713    0.561674                  \n",
      "    33     0.844745   1.21745    0.577533                  \n",
      "    34     0.832687   1.229452   0.569163                  \n",
      "    35     0.82378    1.224427   0.572247                  \n",
      "    36     0.825932   1.24209    0.570485                  \n",
      "    37     0.81289    1.236787   0.57533                   \n",
      "    38     0.798552   1.246952   0.572247                  \n",
      "    39     0.793686   1.24505    0.562555                  \n",
      "    40     0.783544   1.245837   0.56652                   \n",
      "    41     0.782885   1.249022   0.574009                  \n",
      "    42     0.775237   1.25852    0.571806                  \n",
      "    43     0.769885   1.243598   0.581498                  \n",
      "    44     0.753377   1.255012   0.570925                  \n",
      "    45     0.753791   1.252172   0.580617                  \n",
      "    46     0.738719   1.259305   0.574009                  \n",
      "    47     0.729831   1.255132   0.577974                  \n",
      "    48     0.71431    1.254873   0.562996                  \n",
      "    49     0.707666   1.255095   0.579736                  \n",
      "    50     0.699401   1.239445   0.581498                  \n",
      "    51     0.697333   1.25356    0.571806                  \n",
      "    52     0.708012   1.261252   0.573568                  \n",
      "    53     0.702659   1.263038   0.577093                  \n",
      "    54     0.681019   1.26893    0.570044                  \n",
      "    55     0.662832   1.263353   0.57533                   \n",
      "    56     0.673633   1.278048   0.570925                  \n",
      "    57     0.667728   1.282785   0.570925                  \n",
      "    58     0.651325   1.276603   0.57489                   \n",
      "    59     0.663499   1.280292   0.579295                  \n",
      "    60     0.660047   1.276523   0.577093                  \n",
      "    61     0.652751   1.273528   0.571806                  \n",
      "    62     0.632752   1.294588   0.573128                  \n",
      "    63     0.628787   1.29375    0.569163                  \n",
      "    64     0.625665   1.289677   0.574009                  \n",
      "    65     0.614137   1.292706   0.570925                  \n",
      "    66     0.617316   1.305364   0.578414                  \n",
      "    67     0.622837   1.28692    0.579736                  \n",
      "    68     0.613882   1.291688   0.576652                  \n",
      "    69     0.599105   1.303609   0.577533                  \n",
      "    70     0.602008   1.308936   0.572247                  \n",
      "    71     0.599438   1.308717   0.571366                  \n",
      "    72     0.598963   1.314151   0.580176                  \n",
      "    73     0.598428   1.316516   0.576211                  \n",
      "    74     0.602351   1.29983    0.576211                  \n",
      "    75     0.592518   1.310525   0.572687                  \n",
      "    76     0.579384   1.323698   0.57533                   \n",
      "    77     0.58479    1.305322   0.57533                   \n",
      "    78     0.583005   1.316112   0.580176                  \n",
      "    79     0.579712   1.342918   0.572247                  \n",
      "    80     0.582151   1.319135   0.584581                  \n",
      "    81     0.57501    1.324165   0.571806                  \n",
      "    82     0.570384   1.33287    0.578855                  \n",
      "    83     0.570252   1.329389   0.576211                  \n",
      "    84     0.562217   1.347803   0.578855                  \n",
      "    85     0.552523   1.337754   0.570044                  \n",
      "    86     0.546674   1.316006   0.5837                    \n",
      "    87     0.533242   1.34333    0.574449                  \n",
      "    88     0.536989   1.351716   0.582379                  \n",
      "    89     0.543825   1.372278   0.57489                   \n",
      "    90     0.542236   1.353865   0.574009                  \n",
      "    91     0.536949   1.329185   0.58326                   \n",
      "    92     0.538413   1.353985   0.572687                  \n",
      "    93     0.54087    1.353143   0.574009                  \n",
      "    94     0.536465   1.358303   0.570485                  \n",
      "    95     0.530186   1.363013   0.576211                  \n",
      "    96     0.530747   1.357378   0.582379                  \n",
      "    97     0.522659   1.360267   0.577533                  \n",
      "    98     0.521587   1.368294   0.576652                  \n",
      "    99     0.532006   1.357942   0.580176                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f7e0c5076544dfb526b4b9e1275d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3e4fdbd2fa48ef9770fdfda6d1b634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.075494   1.683606   0.424229  \n",
      "    1      1.779713   1.578465   0.454626                 \n",
      "    2      1.641441   1.512408   0.472687                 \n",
      "    3      1.540287   1.453068   0.493833                 \n",
      "    4      1.470331   1.439515   0.503524                 \n",
      "    5      1.424656   1.390363   0.509251                 \n",
      "    6      1.375353   1.372593   0.514097                 \n",
      "    7      1.344349   1.346982   0.519383                 \n",
      "    8      1.298948   1.339111   0.526872                 \n",
      "    9      1.263226   1.330409   0.535242                 \n",
      "    10     1.227147   1.311091   0.545374                 \n",
      "    11     1.211222   1.303971   0.533921                 \n",
      "    12     1.177912   1.291893   0.540088                 \n",
      "    13     1.154132   1.288125   0.543172                 \n",
      "    14     1.114563   1.26843    0.552423                  \n",
      "    15     1.107407   1.26738    0.548458                  \n",
      "    16     1.094031   1.266437   0.549339                  \n",
      "    17     1.078174   1.26773    0.54978                  \n",
      "    18     1.043073   1.265745   0.551101                 \n",
      "    19     1.026795   1.248664   0.553744                 \n",
      "    20     1.013034   1.254378   0.55815                  \n",
      "    21     1.007307   1.253382   0.550661                  \n",
      "    22     0.984859   1.227852   0.570925                  \n",
      "    23     0.968145   1.251252   0.556828                  \n",
      "    24     0.963934   1.244758   0.556388                  \n",
      "    25     0.950469   1.239331   0.562555                  \n",
      "    26     0.933601   1.243837   0.559031                  \n",
      "    27     0.915774   1.256032   0.564758                  \n",
      "    28     0.899818   1.251378   0.56652                   \n",
      "    29     0.873223   1.258078   0.559471                  \n",
      "    30     0.874891   1.248853   0.55815                   \n",
      "    31     0.879234   1.252155   0.570044                  \n",
      "    32     0.844714   1.264034   0.552863                  \n",
      "    33     0.848132   1.253485   0.572687                  \n",
      "    34     0.834591   1.248647   0.570925                  \n",
      "    35     0.822701   1.250498   0.570925                  \n",
      "    36     0.809815   1.253437   0.562115                  \n",
      "    37     0.803793   1.256872   0.567841                  \n",
      "    38     0.80096    1.277903   0.571806                  \n",
      "    39     0.793926   1.246758   0.572687                  \n",
      "    40     0.783387   1.260489   0.57489                   \n",
      "    41     0.779126   1.264857   0.573568                  \n",
      "    42     0.772708   1.268687   0.568282                  \n",
      "    43     0.753853   1.265424   0.567841                  \n",
      "    44     0.730712   1.270076   0.575771                  \n",
      "    45     0.738977   1.264173   0.578855                  \n",
      "    46     0.737918   1.268816   0.571806                  \n",
      "    47     0.73373    1.263419   0.581498                  \n",
      "    48     0.729436   1.254355   0.571366                  \n",
      "    49     0.71666    1.278543   0.570485                  \n",
      "    50     0.712939   1.288562   0.580617                  \n",
      "    51     0.699816   1.266059   0.573568                  \n",
      "    52     0.707247   1.287114   0.570925                  \n",
      "    53     0.687895   1.296884   0.574009                  \n",
      "    54     0.672657   1.291242   0.577974                  \n",
      "    55     0.667676   1.298142   0.580176                  \n",
      "    56     0.663747   1.289106   0.580176                  \n",
      "    57     0.654048   1.282678   0.582379                  \n",
      "    58     0.645767   1.299237   0.577974                  \n",
      "    59     0.643469   1.321084   0.582379                  \n",
      "    60     0.649617   1.298607   0.57533                   \n",
      "    61     0.629038   1.307962   0.57533                   \n",
      "    62     0.632213   1.318479   0.570485                  \n",
      "    63     0.627474   1.313982   0.578414                  \n",
      "    64     0.625985   1.3062     0.575771                  \n",
      "    65     0.614482   1.315393   0.576211                  \n",
      "    66     0.594757   1.313655   0.572687                  \n",
      "    67     0.612589   1.329012   0.573128                  \n",
      "    68     0.608096   1.311635   0.579295                  \n",
      "    69     0.604778   1.315446   0.580176                  \n",
      "    70     0.595048   1.327016   0.569604                  \n",
      "    71     0.612125   1.321792   0.573568                  \n",
      "    72     0.604764   1.346719   0.574009                  \n",
      "    73     0.591549   1.347218   0.575771                  \n",
      "    74     0.583668   1.34822    0.570044                  \n",
      "    75     0.58555    1.35275    0.579295                  \n",
      "    76     0.588123   1.342449   0.571366                  \n",
      "    77     0.580142   1.346865   0.573128                  \n",
      "    78     0.572497   1.343061   0.578855                  \n",
      "    79     0.565284   1.362719   0.577533                  \n",
      "    80     0.564629   1.357983   0.577974                  \n",
      "    81     0.552595   1.357771   0.578855                  \n",
      "    82     0.560275   1.358738   0.579295                  \n",
      "    83     0.5608     1.364782   0.577974                  \n",
      "    84     0.559938   1.360532   0.581938                  \n",
      "    85     0.539334   1.380655   0.570925                  \n",
      "    86     0.553282   1.359173   0.581057                  \n",
      "    87     0.542872   1.362663   0.576652                  \n",
      "    88     0.53685    1.380894   0.577093                  \n",
      "    89     0.535484   1.366176   0.57533                   \n",
      "    90     0.538974   1.368608   0.579736                  \n",
      "    91     0.538992   1.372932   0.573128                  \n",
      "    92     0.537804   1.391321   0.57489                   \n",
      "    93     0.523144   1.385607   0.575771                  \n",
      "    94     0.530428   1.377466   0.573128                  \n",
      "    95     0.526618   1.38219    0.581938                  \n",
      "    96     0.510191   1.370065   0.578855                  \n",
      "    97     0.52837    1.383226   0.574449                  \n",
      "    98     0.517411   1.394408   0.5837                    \n",
      "    99     0.515679   1.372456   0.578855                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcb78b42b7f49d0a4e7f821866a39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9941c1e12c443e8971c551606c49bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.062443   1.663398   0.444493  \n",
      "    1      1.776037   1.548098   0.463436                 \n",
      "    2      1.638831   1.489166   0.476211                 \n",
      "    3      1.545082   1.43153    0.493392                 \n",
      "    4      1.470115   1.401145   0.504846                 \n",
      "    5      1.410552   1.374518   0.519383                 \n",
      "    6      1.352297   1.355153   0.515419                 \n",
      "    7      1.322183   1.355286   0.520705                 \n",
      "    8      1.287429   1.327886   0.52467                  \n",
      "    9      1.243965   1.312452   0.537445                 \n",
      "    10     1.227162   1.303163   0.528634                 \n",
      "    11     1.190456   1.282146   0.539648                  \n",
      "    12     1.169072   1.300047   0.543612                 \n",
      "    13     1.163871   1.280539   0.54141                  \n",
      "    14     1.13802    1.266065   0.54978                  \n",
      "    15     1.102924   1.285507   0.540969                 \n",
      "    16     1.075641   1.251691   0.556388                 \n",
      "    17     1.071395   1.259543   0.548899                 \n",
      "    18     1.052473   1.243318   0.555066                 \n",
      "    19     1.012981   1.246201   0.548899                 \n",
      "    20     1.007469   1.257393   0.551982                  \n",
      "    21     1.009554   1.259031   0.55859                   \n",
      "    22     0.990582   1.252038   0.559912                  \n",
      "    23     0.966252   1.247038   0.560352                  \n",
      "    24     0.958306   1.245659   0.555507                  \n",
      "    25     0.948318   1.235333   0.567401                  \n",
      "    26     0.93578    1.233426   0.566079                  \n",
      "    27     0.935838   1.238859   0.561233                  \n",
      "    28     0.907775   1.224096   0.567401                  \n",
      "    29     0.906599   1.226677   0.567841                  \n",
      "    30     0.891718   1.241153   0.565639                  \n",
      "    31     0.863218   1.248854   0.566079                  \n",
      "    32     0.859152   1.248365   0.569163                  \n",
      "    33     0.855383   1.233875   0.577093                  \n",
      "    34     0.834122   1.238611   0.570044                  \n",
      "    35     0.828239   1.248949   0.572687                  \n",
      "    36     0.824683   1.260305   0.55815                   \n",
      "    37     0.815769   1.245186   0.573128                  \n",
      "    38     0.79544    1.268465   0.559471                  \n",
      "    39     0.780015   1.261211   0.560352                  \n",
      "    40     0.780307   1.253084   0.571806                  \n",
      "    41     0.77633    1.25749    0.567401                  \n",
      "    42     0.76967    1.263784   0.569604                  \n",
      "    43     0.762318   1.252177   0.571366                  \n",
      "    44     0.744778   1.262979   0.573568                  \n",
      "    45     0.745106   1.260878   0.577974                  \n",
      "    46     0.715381   1.252233   0.573128                  \n",
      "    47     0.716904   1.26145    0.5837                    \n",
      "    48     0.718529   1.267549   0.571366                  \n",
      "    49     0.709913   1.248146   0.574449                  \n",
      "    50     0.709889   1.289206   0.570925                  \n",
      "    51     0.690309   1.276471   0.57489                   \n",
      "    52     0.689102   1.289293   0.574009                  \n",
      "    53     0.683471   1.288398   0.57489                   \n",
      "    54     0.689755   1.281035   0.573568                  \n",
      "    55     0.670795   1.285897   0.573128                  \n",
      "    56     0.672403   1.269652   0.577974                  \n",
      "    57     0.651142   1.291605   0.568282                  \n",
      "    58     0.656809   1.287369   0.568282                  \n",
      "    59     0.644861   1.299079   0.573128                  \n",
      "    60     0.641681   1.311967   0.578414                  \n",
      "    61     0.64902    1.312032   0.575771                  \n",
      "    62     0.634813   1.306359   0.575771                  \n",
      "    63     0.631549   1.318573   0.571806                  \n",
      "    64     0.623085   1.312025   0.57533                   \n",
      "    65     0.632055   1.299325   0.573568                  \n",
      "    66     0.62364    1.302249   0.581498                  \n",
      "    67     0.607671   1.328748   0.570044                  \n",
      "    68     0.605436   1.327204   0.57489                   \n",
      "    69     0.599604   1.334359   0.573568                  \n",
      "    70     0.602465   1.328671   0.570925                  \n",
      "    71     0.605789   1.332571   0.57489                   \n",
      "    72     0.597582   1.319375   0.571806                  \n",
      "    73     0.600089   1.324841   0.574449                  \n",
      "    74     0.591556   1.326467   0.57489                   \n",
      "    75     0.585044   1.319636   0.57533                   \n",
      "    76     0.586158   1.341046   0.572687                  \n",
      "    77     0.588452   1.351774   0.571806                  \n",
      "    78     0.579756   1.328531   0.577093                  \n",
      "    79     0.5727     1.32358    0.579295                  \n",
      "    80     0.555496   1.344226   0.574449                  \n",
      "    81     0.561796   1.33941    0.575771                  \n",
      "    82     0.552922   1.343233   0.571806                  \n",
      "    83     0.559871   1.336888   0.578855                  \n",
      "    84     0.556379   1.35734    0.57489                   \n",
      "    85     0.553673   1.343586   0.577533                  \n",
      "    86     0.544566   1.352722   0.577093                  \n",
      "    87     0.552387   1.351653   0.572247                  \n",
      "    88     0.549699   1.363618   0.57533                   \n",
      "    89     0.548799   1.37392    0.578414                  \n",
      "    90     0.542539   1.372811   0.581057                  \n",
      "    91     0.542891   1.361707   0.585463                  \n",
      "    92     0.531063   1.35893    0.579736                  \n",
      "    93     0.537831   1.373719   0.57489                   \n",
      "    94     0.519922   1.352708   0.580617                  \n",
      "    95     0.528215   1.357008   0.576652                  \n",
      "    96     0.536591   1.373817   0.570044                  \n",
      "    97     0.520008   1.358973   0.577974                  \n",
      "    98     0.510228   1.377737   0.57489                   \n",
      "    99     0.516118   1.388451   0.580617                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad8c16be5094f00aeaa5426c0366d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a074e5dd3d04b90be41dc158fa36b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.063038   1.685731   0.414978  \n",
      "    1      1.764446   1.562178   0.446256                 \n",
      "    2      1.629279   1.484249   0.489868                 \n",
      "    3      1.532227   1.438738   0.500881                 \n",
      "    4      1.477964   1.408984   0.501322                  \n",
      "    5      1.423282   1.376824   0.515419                 \n",
      "    6      1.368953   1.359803   0.518502                 \n",
      "    7      1.332311   1.32568    0.527313                 \n",
      "    8      1.301508   1.331131   0.531278                 \n",
      "    9      1.270664   1.316045   0.52511                  \n",
      "    10     1.232052   1.309361   0.540969                 \n",
      "    11     1.203517   1.283983   0.551542                 \n",
      "    12     1.178116   1.283642   0.540969                 \n",
      "    13     1.146628   1.274553   0.542291                 \n",
      "    14     1.122978   1.273328   0.544493                 \n",
      "    15     1.103877   1.254887   0.546256                 \n",
      "    16     1.098853   1.245758   0.553304                 \n",
      "    17     1.064548   1.241274   0.556388                 \n",
      "    18     1.056443   1.239816   0.552863                 \n",
      "    19     1.025071   1.247898   0.562115                 \n",
      "    20     1.009709   1.236014   0.554626                  \n",
      "    21     0.995386   1.234132   0.565639                  \n",
      "    22     0.976999   1.237378   0.56652                   \n",
      "    23     0.968265   1.235901   0.559471                  \n",
      "    24     0.944112   1.232805   0.565639                  \n",
      "    25     0.932632   1.252535   0.570485                  \n",
      "    26     0.924317   1.251092   0.568282                  \n",
      "    27     0.900806   1.247077   0.573568                  \n",
      "    28     0.887689   1.253485   0.563436                  \n",
      "    29     0.877175   1.229163   0.566079                  \n",
      "    30     0.869667   1.236237   0.562555                  \n",
      "    31     0.858448   1.231937   0.564758                  \n",
      "    32     0.851275   1.237297   0.560793                  \n",
      "    33     0.848658   1.25615    0.559912                  \n",
      "    34     0.833622   1.237706   0.57489                   \n",
      "    35     0.818996   1.232768   0.575771                  \n",
      "    36     0.817022   1.241483   0.576211                  \n",
      "    37     0.812401   1.242255   0.562996                  \n",
      "    38     0.790562   1.24235    0.571806                  \n",
      "    39     0.779722   1.240996   0.567401                  \n",
      "    40     0.780765   1.237669   0.574449                  \n",
      "    41     0.77874    1.229291   0.577974                  \n",
      "    42     0.761704   1.252035   0.579736                  \n",
      "    43     0.747165   1.250186   0.578855                  \n",
      "    44     0.741849   1.251826   0.572687                  \n",
      "    45     0.744496   1.251719   0.577093                  \n",
      "    46     0.731371   1.261012   0.577533                  \n",
      "    47     0.71691    1.26125    0.573568                  \n",
      "    48     0.711      1.258218   0.578414                  \n",
      "    49     0.717946   1.267067   0.577533                  \n",
      "    50     0.695143   1.250676   0.578855                  \n",
      "    51     0.685033   1.259428   0.582819                  \n",
      "    52     0.673646   1.250991   0.579736                  \n",
      "    53     0.674086   1.269505   0.567841                  \n",
      "    54     0.668926   1.293354   0.571806                  \n",
      "    55     0.655099   1.274897   0.57533                   \n",
      "    56     0.660832   1.26469    0.579736                  \n",
      "    57     0.65028    1.285875   0.578414                  \n",
      "    58     0.649868   1.301253   0.570044                  \n",
      "    59     0.656104   1.295233   0.57489                   \n",
      "    60     0.63573    1.304906   0.576211                  \n",
      "    61     0.642161   1.30534    0.573568                  \n",
      "    62     0.634431   1.303905   0.581498                  \n",
      "    63     0.635568   1.304759   0.576652                  \n",
      "    64     0.612396   1.316779   0.573128                  \n",
      "    65     0.617074   1.31277    0.571806                  \n",
      "    66     0.61839    1.290045   0.586344                  \n",
      "    67     0.604378   1.30293    0.585463                  \n",
      "    68     0.606583   1.285521   0.587665                  \n",
      "    69     0.596622   1.316977   0.574009                  \n",
      "    70     0.588816   1.332106   0.579295                  \n",
      "    71     0.596144   1.317058   0.584581                  \n",
      "    72     0.599094   1.331294   0.567841                  \n",
      "    73     0.598356   1.320495   0.576211                  \n",
      "    74     0.59475    1.346378   0.577974                  \n",
      "    75     0.58267    1.33141    0.580176                  \n",
      "    76     0.585739   1.322227   0.573128                  \n",
      "    77     0.575765   1.322111   0.579736                  \n",
      "    78     0.574471   1.336176   0.577093                  \n",
      "    79     0.576711   1.335577   0.577093                  \n",
      "    80     0.565435   1.338353   0.580176                  \n",
      "    81     0.554857   1.33795    0.585903                  \n",
      "    82     0.56374    1.340567   0.584581                  \n",
      "    83     0.553309   1.348809   0.576211                  \n",
      "    84     0.551412   1.358848   0.581057                  \n",
      "    85     0.558042   1.357684   0.574009                  \n",
      "    86     0.551905   1.36028    0.581498                  \n",
      "    87     0.550556   1.348372   0.580617                  \n",
      "    88     0.542914   1.381632   0.570044                  \n",
      "    89     0.555214   1.356747   0.57533                   \n",
      "    90     0.542039   1.364326   0.577093                  \n",
      "    91     0.539687   1.351619   0.584581                  \n",
      "    92     0.53683    1.3601     0.582379                  \n",
      "    93     0.527664   1.356562   0.577974                  \n",
      "    94     0.525304   1.369646   0.58326                   \n",
      "    95     0.518841   1.374023   0.57489                   \n",
      "    96     0.517762   1.38612    0.576211                  \n",
      "    97     0.517446   1.391403   0.580617                  \n",
      "    98     0.521129   1.39756    0.577093                  \n",
      "    99     0.521802   1.400581   0.575771                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9075340acffa4092919493931038bbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865efc42ee2342e1ae0f5594e4ef53b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.092233   1.66641    0.439207  \n",
      "    1      1.77948    1.570702   0.466079                 \n",
      "    2      1.640784   1.530033   0.473128                 \n",
      "    3      1.553381   1.45206    0.505727                 \n",
      "    4      1.483861   1.407587   0.502643                 \n",
      "    5      1.408491   1.382125   0.514978                 \n",
      "    6      1.369511   1.356664   0.518062                 \n",
      "    7      1.335667   1.330133   0.526872                 \n",
      "    8      1.297144   1.331242   0.530837                 \n",
      "    9      1.26276    1.325361   0.535242                 \n",
      "    10     1.226886   1.302318   0.543172                 \n",
      "    11     1.19639    1.287066   0.537445                 \n",
      "    12     1.179546   1.274258   0.551101                 \n",
      "    13     1.142277   1.286925   0.542731                 \n",
      "    14     1.119497   1.278839   0.552423                 \n",
      "    15     1.113673   1.276885   0.543172                 \n",
      "    16     1.101442   1.274828   0.549339                 \n",
      "    17     1.07559    1.268418   0.547137                 \n",
      "    18     1.046303   1.257605   0.55859                  \n",
      "    19     1.046479   1.255339   0.548899                 \n",
      "    20     1.026121   1.251414   0.552423                 \n",
      "    21     1.005967   1.24022    0.566079                  \n",
      "    22     0.979808   1.243236   0.564758                  \n",
      "    23     0.965909   1.243516   0.562555                  \n",
      "    24     0.950411   1.23327    0.561233                  \n",
      "    25     0.950121   1.251428   0.552863                  \n",
      "    26     0.930295   1.237937   0.56696                   \n",
      "    27     0.912668   1.216823   0.567841                  \n",
      "    28     0.897113   1.238984   0.554626                  \n",
      "    29     0.8972     1.224945   0.574009                  \n",
      "    30     0.878712   1.22579    0.567401                  \n",
      "    31     0.868047   1.239424   0.571366                  \n",
      "    32     0.869927   1.230105   0.567401                  \n",
      "    33     0.849951   1.250502   0.577093                  \n",
      "    34     0.83534    1.238273   0.570044                  \n",
      "    35     0.831019   1.228913   0.572247                  \n",
      "    36     0.822903   1.243414   0.56696                   \n",
      "    37     0.807009   1.217993   0.574449                  \n",
      "    38     0.796615   1.239111   0.571366                  \n",
      "    39     0.804418   1.235998   0.572687                  \n",
      "    40     0.783717   1.230258   0.581057                  \n",
      "    41     0.75567    1.264375   0.569163                  \n",
      "    42     0.758225   1.253266   0.580176                  \n",
      "    43     0.751797   1.246273   0.574009                  \n",
      "    44     0.740641   1.270221   0.578414                  \n",
      "    45     0.738565   1.259341   0.577974                  \n",
      "    46     0.721246   1.268334   0.576652                  \n",
      "    47     0.725466   1.264951   0.562555                  \n",
      "    48     0.709181   1.261459   0.581938                  \n",
      "    49     0.70521    1.269069   0.577974                  \n",
      "    50     0.702128   1.258461   0.581938                  \n",
      "    51     0.691415   1.284905   0.574009                  \n",
      "    52     0.690411   1.286622   0.574449                  \n",
      "    53     0.669258   1.280392   0.572247                  \n",
      "    54     0.668009   1.280091   0.569604                  \n",
      "    55     0.666808   1.289539   0.578414                  \n",
      "    56     0.665906   1.264117   0.574449                  \n",
      "    57     0.65869    1.272242   0.57533                   \n",
      "    58     0.658447   1.284299   0.57489                   \n",
      "    59     0.654495   1.292735   0.576211                  \n",
      "    60     0.653054   1.282331   0.578414                  \n",
      "    61     0.640931   1.285013   0.579736                  \n",
      "    62     0.637917   1.296714   0.580617                  \n",
      "    63     0.633387   1.300758   0.57533                   \n",
      "    64     0.627186   1.315552   0.584581                  \n",
      "    65     0.632659   1.30224    0.574009                  \n",
      "    66     0.620838   1.303425   0.57533                   \n",
      "    67     0.625691   1.306981   0.579295                  \n",
      "    68     0.603353   1.312878   0.575771                  \n",
      "    69     0.610883   1.304383   0.579736                  \n",
      "    70     0.603214   1.308455   0.573128                  \n",
      "    71     0.60852    1.317215   0.581057                  \n",
      "    72     0.594098   1.32505    0.577974                  \n",
      "    73     0.590706   1.335055   0.581498                  \n",
      "    74     0.596135   1.319191   0.585463                  \n",
      "    75     0.573533   1.325983   0.582819                  \n",
      "    76     0.571882   1.340843   0.577533                  \n",
      "    77     0.572486   1.334301   0.576211                  \n",
      "    78     0.571341   1.34501    0.57489                   \n",
      "    79     0.572318   1.354834   0.579295                  \n",
      "    80     0.573924   1.326541   0.580617                  \n",
      "    81     0.562373   1.335304   0.587225                  \n",
      "    82     0.557024   1.350793   0.576211                  \n",
      "    83     0.545388   1.344333   0.581938                  \n",
      "    84     0.554698   1.346695   0.577533                  \n",
      "    85     0.553998   1.340306   0.581938                  \n",
      "    86     0.556351   1.345865   0.580176                  \n",
      "    87     0.542009   1.352629   0.57533                   \n",
      "    88     0.537526   1.365588   0.582819                  \n",
      "    89     0.547919   1.347948   0.571806                  \n",
      "    90     0.541706   1.347712   0.581057                  \n",
      "    91     0.542822   1.366781   0.575771                  \n",
      "    92     0.542444   1.34839    0.581498                  \n",
      "    93     0.534594   1.365605   0.584141                  \n",
      "    94     0.539153   1.359789   0.582819                  \n",
      "    95     0.532851   1.37398    0.575771                  \n",
      "    96     0.522977   1.377583   0.572247                  \n",
      "    97     0.529173   1.367637   0.580617                  \n",
      "    98     0.52192    1.384791   0.574449                  \n",
      "    99     0.515404   1.374972   0.5837                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b75f1f8a634648ba5ed349cf55f032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acc1be4db584fee9b6e267e40e2bba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.073422   1.672556   0.421145  \n",
      "    1      1.78585    1.555015   0.467401                  \n",
      "    2      1.6399     1.500961   0.480176                 \n",
      "    3      1.535749   1.469025   0.496035                 \n",
      "    4      1.471203   1.413403   0.505286                 \n",
      "    5      1.416234   1.393401   0.5163                   \n",
      "    6      1.371151   1.362424   0.518943                 \n",
      "    7      1.333243   1.342789   0.515859                 \n",
      "    8      1.297632   1.323096   0.525551                 \n",
      "    9      1.261791   1.310451   0.527313                 \n",
      "    10     1.246923   1.316659   0.530396                  \n",
      "    11     1.202701   1.285658   0.542731                 \n",
      "    12     1.176799   1.281872   0.531718                 \n",
      "    13     1.150727   1.283171   0.559031                 \n",
      "    14     1.13559    1.270559   0.54185                  \n",
      "    15     1.115756   1.252159   0.556388                 \n",
      "    16     1.087247   1.266576   0.556388                 \n",
      "    17     1.067686   1.25056    0.54978                  \n",
      "    18     1.043652   1.245754   0.553304                 \n",
      "    19     1.033374   1.245411   0.549339                  \n",
      "    20     1.015014   1.249342   0.559471                 \n",
      "    21     1.002509   1.255472   0.55859                   \n",
      "    22     0.981496   1.231795   0.562555                  \n",
      "    23     0.96672    1.260306   0.555066                  \n",
      "    24     0.962011   1.234443   0.566079                  \n",
      "    25     0.940698   1.228773   0.562115                  \n",
      "    26     0.919939   1.244318   0.559912                  \n",
      "    27     0.913558   1.229251   0.55859                   \n",
      "    28     0.904666   1.238135   0.566079                  \n",
      "    29     0.886347   1.234784   0.556828                  \n",
      "    30     0.872066   1.231709   0.573568                  \n",
      "    31     0.862967   1.233465   0.574009                  \n",
      "    32     0.852109   1.229551   0.565198                  \n",
      "    33     0.842835   1.241642   0.569604                  \n",
      "    34     0.833483   1.250433   0.572247                  \n",
      "    35     0.829854   1.235461   0.562555                  \n",
      "    36     0.817812   1.231803   0.567841                  \n",
      "    37     0.805246   1.236993   0.570485                  \n",
      "    38     0.794509   1.239937   0.572687                  \n",
      "    39     0.796835   1.242397   0.57533                   \n",
      "    40     0.779457   1.22953    0.576211                  \n",
      "    41     0.767685   1.254809   0.572247                  \n",
      "    42     0.756751   1.241125   0.573568                  \n",
      "    43     0.744145   1.254719   0.571806                  \n",
      "    44     0.731371   1.26692    0.570925                  \n",
      "    45     0.729119   1.263138   0.571806                  \n",
      "    46     0.722479   1.280348   0.567841                  \n",
      "    47     0.727511   1.269451   0.57489                   \n",
      "    48     0.718363   1.278384   0.572687                  \n",
      "    49     0.708417   1.24448    0.574009                  \n",
      "    50     0.70539    1.254054   0.571806                  \n",
      "    51     0.702167   1.261879   0.576211                  \n",
      "    52     0.696332   1.277509   0.572247                  \n",
      "    53     0.680082   1.277425   0.570044                  \n",
      "    54     0.684374   1.285754   0.571366                  \n",
      "    55     0.676749   1.27217    0.569604                  \n",
      "    56     0.661007   1.279353   0.572247                  \n",
      "    57     0.641599   1.289801   0.564758                  \n",
      "    58     0.646633   1.290869   0.568282                  \n",
      "    59     0.642315   1.275819   0.579295                  \n",
      "    60     0.648918   1.286891   0.575771                  \n",
      "    61     0.653052   1.299599   0.577974                  \n",
      "    62     0.640775   1.285095   0.577974                  \n",
      "    63     0.626958   1.298711   0.571806                  \n",
      "    64     0.621375   1.293724   0.571806                  \n",
      "    65     0.619946   1.298505   0.578414                  \n",
      "    66     0.618514   1.292624   0.56652                   \n",
      "    67     0.613679   1.308967   0.573128                  \n",
      "    68     0.614419   1.303993   0.574009                  \n",
      "    69     0.608449   1.327613   0.577533                  \n",
      "    70     0.613563   1.307713   0.581498                  \n",
      "    71     0.597105   1.294812   0.582819                  \n",
      "    72     0.604979   1.310511   0.571806                  \n",
      "    73     0.600645   1.299575   0.581938                  \n",
      "    74     0.58177    1.297141   0.585022                  \n",
      "    75     0.585393   1.319328   0.573128                  \n",
      "    76     0.577059   1.330453   0.577974                  \n",
      "    77     0.572723   1.314296   0.576211                  \n",
      "    78     0.575624   1.336531   0.576211                  \n",
      "    79     0.570904   1.337913   0.580617                  \n",
      "    80     0.560902   1.351961   0.574009                  \n",
      "    81     0.554852   1.34582    0.576652                  \n",
      "    82     0.555505   1.346387   0.572687                  \n",
      "    83     0.550647   1.341424   0.577093                  \n",
      "    84     0.558332   1.341034   0.573568                  \n",
      "    85     0.55662    1.332443   0.576211                  \n",
      "    86     0.552798   1.355181   0.577533                  \n",
      "    87     0.529936   1.359744   0.581057                  \n",
      "    88     0.537456   1.344739   0.582819                  \n",
      "    89     0.531228   1.345493   0.57533                   \n",
      "    90     0.538963   1.356747   0.576652                  \n",
      "    91     0.528927   1.34415    0.580617                  \n",
      "    92     0.529964   1.345165   0.579295                  \n",
      "    93     0.529157   1.359101   0.580176                  \n",
      "    94     0.526426   1.363447   0.582379                  \n",
      "    95     0.539749   1.364333   0.581057                  \n",
      "    96     0.540684   1.360261   0.579295                  \n",
      "    97     0.524493   1.35109    0.570044                  \n",
      "    98     0.511249   1.356715   0.574009                  \n",
      "    99     0.5169     1.373261   0.576652                  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e721c438e6a48538324f609fb16294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce1df361d5f4bdc8ca8ed85f91f1ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      2.079844   1.667367   0.437885  \n",
      "    1      1.78055    1.552633   0.460352                 \n",
      "    2      1.629926   1.490917   0.473128                 \n",
      "    3      1.545215   1.448304   0.486344                 \n",
      "    4      1.472309   1.40425    0.501762                 \n",
      "    5      1.414946   1.394346   0.512775                 \n",
      "    6      1.36355    1.383962   0.5163                   \n",
      "    7      1.319522   1.321849   0.523348                 \n",
      "    8      1.275387   1.317617   0.534802                 \n",
      "    9      1.250435   1.306414   0.537445                 \n",
      "    10     1.23389    1.315801   0.537445                 \n",
      "    11     1.198433   1.29526    0.53348                  \n",
      "    12     1.172579   1.276422   0.551982                 \n",
      "    13     1.13823    1.261909   0.548458                 \n",
      "    14     1.134498   1.275434   0.551542                 \n",
      "    15     1.109187   1.265567   0.55815                  \n",
      "    16     1.070774   1.244929   0.560352                 \n",
      "    17     1.053425   1.26178    0.555066                 \n",
      "    18     1.051553   1.255539   0.55859                  \n",
      "    19     1.028659   1.252547   0.569604                 \n",
      "    20     1.020991   1.241583   0.568282                 \n",
      "    21     1.002164   1.247752   0.554626                  \n",
      "    22     0.980886   1.231503   0.564758                  \n",
      "    23     0.978752   1.23358    0.557709                  \n",
      "    24     0.968178   1.228073   0.563877                  \n",
      "    25     0.93823    1.233811   0.568722                  \n",
      "    26     0.928189   1.218977   0.560352                  \n",
      "    27     0.911055   1.233415   0.565198                  \n",
      "    28     0.892692   1.234655   0.56696                   \n",
      "    29     0.905471   1.240137   0.553304                  \n",
      "    30     0.887063   1.227952   0.570925                  \n",
      "    31     0.856495   1.223512   0.573568                  \n",
      "    32     0.851112   1.232345   0.563436                  \n",
      "    33     0.837491   1.236649   0.569163                  \n",
      "    34     0.829297   1.230773   0.561674                  \n",
      "    35     0.814918   1.2382     0.563436                  \n",
      "    36     0.808984   1.241721   0.574009                  \n",
      "    37     0.802426   1.245236   0.575771                  \n",
      "    38     0.791533   1.254625   0.563877                  \n",
      "    39     0.787869   1.235395   0.569604                  \n",
      "    40     0.769272   1.251357   0.572247                  \n",
      "    41     0.76611    1.252135   0.567841                  \n",
      "    42     0.761276   1.259336   0.572247                  \n",
      "    43     0.756012   1.258321   0.570485                  \n",
      "    44     0.744707   1.265302   0.57533                   \n",
      "    45     0.748821   1.27174    0.577974                  \n",
      "    46     0.722121   1.268621   0.563877                  \n",
      "    47     0.715512   1.25019    0.577533                  \n",
      "    48     0.704279   1.274435   0.571806                  \n",
      "    49     0.69861    1.258397   0.57489                   \n",
      "    50     0.700187   1.275637   0.57533                   \n",
      "    51     0.695658   1.277425   0.581938                  \n",
      "    52     0.688594   1.265035   0.576652                  \n",
      "    53     0.697904   1.263035   0.576652                  \n",
      "    54     0.684133   1.267234   0.577533                  \n",
      "    55     0.672494   1.278875   0.571366                  \n",
      "    56     0.672813   1.286761   0.578855                  \n",
      "    57     0.652733   1.277251   0.57489                   \n",
      "    58     0.652456   1.280341   0.584141                  \n",
      "    59     0.648974   1.274637   0.579295                  \n",
      "    60     0.6541     1.274243   0.580617                  \n",
      "    61     0.640797   1.283525   0.576652                  \n",
      "    62     0.63522    1.303861   0.581057                  \n",
      "    63     0.64064    1.284992   0.570925                  \n",
      "    64     0.628456   1.300272   0.578414                  \n",
      "    65     0.624142   1.305006   0.574449                  \n",
      "    66     0.616739   1.29351    0.584581                  \n",
      "    67     0.60451    1.300512   0.574449                  \n",
      "    68     0.618969   1.301423   0.581938                  \n",
      "    69     0.602469   1.291651   0.571806                  \n",
      "    70     0.59667    1.295743   0.573128                  \n",
      "    71     0.57996    1.313535   0.5837                    \n",
      "    72     0.596301   1.316917   0.5837                    \n",
      "    73     0.60016    1.330236   0.57489                   \n",
      "    74     0.586173   1.326819   0.577093                  \n",
      "    75     0.58119    1.332691   0.580176                  \n",
      "    76     0.580265   1.320914   0.582379                  \n",
      "    77     0.580929   1.337448   0.577533                  \n",
      "    78     0.560998   1.320129   0.580617                  \n",
      "    79     0.562706   1.334938   0.580176                  \n",
      "    80     0.568109   1.333266   0.579295                  \n",
      "    81     0.561945   1.344288   0.575771                  \n",
      "    82     0.56563    1.353176   0.580617                  \n",
      "    83     0.563814   1.328835   0.581498                  \n",
      "    84     0.553628   1.3299     0.573568                  \n",
      "    85     0.556329   1.339529   0.58326                   \n",
      "    86     0.562127   1.333494   0.575771                  \n",
      "    87     0.543208   1.334137   0.573568                  \n",
      "    88     0.528103   1.333981   0.586344                  \n",
      "    89     0.538499   1.353932   0.582819                  \n",
      "    90     0.535755   1.342434   0.582379                  \n",
      "    91     0.534948   1.349747   0.578855                  \n",
      "    92     0.544857   1.343952   0.578855                  \n",
      "    93     0.534169   1.351617   0.577533                  \n",
      "    94     0.523051   1.343115   0.574009                  \n",
      "    95     0.522192   1.361591   0.571366                  \n",
      "    96     0.532037   1.356464   0.574449                  \n",
      "    97     0.513974   1.354159   0.574009                  \n",
      "    98     0.510911   1.364187   0.579295                  \n",
      "    99     0.523939   1.365585   0.579736                  \n"
     ]
    }
   ],
   "source": [
    "v_a = k_fold_cross_loop1(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=0.5796446\n",
      "stdev.=0.0024449785765932545\n"
     ]
    }
   ],
   "source": [
    "valacc = [0.581498,0.57709,0.58239,0.580176,0.578855,0.580617,0.57577,0.5837,0.57665,0.5797]\n",
    "print('mean='+str(np.mean(valacc)))\n",
    "print('stdev.='+str(np.std(valacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9cc390f3c63c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d70d1fd7ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "\n",
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)\n",
    "adj = cm.transpose()/cm.sum(axis=1)\n",
    "adj = adj.round(2)\n",
    "plot_confusion_matrix(adj.transpose(), data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703069703d7749b4959b3ec116063a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 71/71 [01:18<00:00,  1.05s/it]\n",
      "100%|| 18/18 [00:19<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588fdcee66474da884b46eb79201ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.267667   1.289242   0.543172  \n",
      "    1      1.24221    1.293281   0.544493                 \n",
      "    2      1.233481   1.27629    0.540529                 \n",
      "    3      1.23161    1.271877   0.543612                 \n",
      "    4      1.236873   1.275465   0.537004                 \n",
      "    5      1.217533   1.269105   0.551101                 \n",
      "    6      1.2        1.257847   0.548458                 \n",
      "    7      1.175196   1.259171   0.55022                  \n",
      "    8      1.167488   1.250896   0.544934                 \n",
      "    9      1.15592    1.278416   0.550661                 \n",
      "    10     1.157006   1.253423   0.552863                 \n",
      "    11     1.15742    1.253472   0.551101                  \n",
      "    12     1.147838   1.252431   0.555947                 \n",
      "    13     1.123004   1.244008   0.548458                 \n",
      "    14     1.11987    1.241218   0.546256                  \n",
      "    15     1.115705   1.247234   0.555066                  \n",
      "    16     1.095273   1.238376   0.556388                 \n",
      "    17     1.098234   1.237258   0.563877                 \n",
      "    18     1.088894   1.235968   0.549339                 \n",
      "    19     1.072944   1.233002   0.555947                 \n",
      "    20     1.075194   1.229227   0.557269                 \n",
      "    21     1.06491    1.233338   0.555507                 \n",
      "    22     1.048114   1.236095   0.559471                 \n",
      "    23     1.054952   1.224796   0.559471                 \n",
      "    24     1.041058   1.243802   0.556388                 \n",
      "    25     1.033636   1.221593   0.561674                  \n",
      "    26     1.02046    1.22503    0.560352                 \n",
      "    27     1.024753   1.23216    0.557269                 \n",
      "    28     1.011683   1.238804   0.567401                  \n",
      "    29     1.015862   1.229995   0.564758                  \n",
      "    30     1.001439   1.230244   0.553744                  \n",
      "    31     0.995771   1.22808    0.559031                  \n",
      "    32     0.983211   1.223669   0.562996                  \n",
      "    33     0.980927   1.218939   0.564758                  \n",
      "    34     0.96937    1.213605   0.56652                   \n",
      "    35     0.961829   1.231537   0.55815                   \n",
      "    36     0.966826   1.21792    0.562996                  \n",
      "    37     0.941626   1.220741   0.565639                  \n",
      "    38     0.944843   1.234988   0.555947                  \n",
      "    39     0.93752    1.227554   0.568722                  \n",
      "    40     0.94052    1.211494   0.560793                  \n",
      "    41     0.93976    1.228469   0.570485                  \n",
      "    42     0.922293   1.215995   0.567401                  \n",
      "    43     0.905079   1.219028   0.563436                  \n",
      "    44     0.903626   1.221683   0.561674                  \n",
      "    45     0.915379   1.227403   0.559471                  \n",
      "    46     0.894423   1.22922    0.561233                  \n",
      "    47     0.902934   1.225842   0.551982                  \n",
      "    48     0.892064   1.229417   0.561674                  \n",
      "    49     0.879614   1.230691   0.565198                  \n",
      "    50     0.874019   1.225061   0.557709                  \n",
      "    51     0.859574   1.226191   0.565198                  \n",
      "    52     0.863044   1.220566   0.560352                  \n",
      "    53     0.863865   1.225015   0.564758                  \n",
      "    54     0.853428   1.220403   0.562115                  \n",
      "    55     0.853541   1.233831   0.557709                  \n",
      "    56     0.86307    1.235933   0.552423                  \n",
      "    57     0.834969   1.235384   0.546696                  \n",
      "    58     0.838473   1.246407   0.560352                  \n",
      "    59     0.839785   1.235156   0.557709                  \n",
      "    60     0.832203   1.242558   0.551982                  \n",
      "    61     0.824017   1.226665   0.562555                  \n",
      "    62     0.817516   1.234777   0.563877                  \n",
      "    63     0.816306   1.235407   0.559471                  \n",
      "    64     0.81965    1.233551   0.562115                  \n",
      "    65     0.809005   1.241294   0.556388                  \n",
      "    66     0.796397   1.242799   0.557709                  \n",
      "    67     0.793246   1.240857   0.568722                  \n",
      "    68     0.792994   1.240294   0.557709                  \n",
      "    69     0.774924   1.243103   0.55859                   \n",
      "    70     0.784114   1.23585    0.55815                   \n",
      "    71     0.785018   1.234168   0.555507                  \n",
      "    72     0.763829   1.234954   0.566079                  \n",
      "    73     0.781006   1.242821   0.557709                  \n",
      "    74     0.782276   1.24891    0.561674                  \n",
      "    75     0.768109   1.244125   0.559471                  \n",
      "    76     0.764491   1.247289   0.555947                  \n",
      "    77     0.758733   1.25189    0.551101                  \n",
      "    78     0.762361   1.247961   0.560352                  \n",
      "    79     0.748988   1.259028   0.559471                  \n",
      "    80     0.752892   1.248447   0.55815                   \n",
      "    81     0.759422   1.245525   0.562115                  \n",
      "    82     0.750723   1.235167   0.561233                  \n",
      "    83     0.73576    1.251861   0.556828                  \n",
      "    84     0.748815   1.25344    0.565198                  \n",
      "    85     0.747166   1.247494   0.566079                  \n",
      "    86     0.737605   1.257672   0.559031                  \n",
      "    87     0.726009   1.262313   0.555947                  \n",
      "    88     0.735466   1.262721   0.55815                   \n",
      "    89     0.739166   1.273559   0.561233                  \n",
      "    90     0.72237    1.273382   0.559912                  \n",
      "    91     0.717151   1.268993   0.55815                   \n",
      "    92     0.718211   1.271525   0.560793                  \n",
      "    93     0.708547   1.264953   0.55859                   \n",
      "    94     0.702976   1.26382    0.562555                  \n",
      "    95     0.696141   1.278233   0.560352                  \n",
      "    96     0.704666   1.269957   0.562555                  \n",
      "    97     0.712623   1.264014   0.564317                  \n",
      "    98     0.701869   1.267199   0.559031                  \n",
      "    99     0.690187   1.277415   0.556388                  \n",
      "   100     0.694731   1.276408   0.559912                  \n",
      "   101     0.708116   1.271386   0.562115                  \n",
      "   102     0.687841   1.272555   0.563877                  \n",
      "   103     0.684142   1.283544   0.562115                  \n",
      "   104     0.675472   1.290297   0.561674                  \n",
      "   105     0.679045   1.282113   0.56696                   \n",
      "   106     0.684818   1.286728   0.55859                   \n",
      "   107     0.679174   1.292066   0.559031                  \n",
      "   108     0.669378   1.281054   0.562115                  \n",
      "   109     0.669722   1.288637   0.562555                  \n",
      "   110     0.656      1.292442   0.563436                  \n",
      "   111     0.669302   1.302476   0.562555                  \n",
      "   112     0.657468   1.301757   0.562115                  \n",
      "   113     0.673276   1.289227   0.559471                  \n",
      "   114     0.660381   1.287064   0.563436                  \n",
      "   115     0.654099   1.292903   0.557269                  \n",
      "   116     0.668299   1.291695   0.559471                  \n",
      "   117     0.655752   1.312907   0.555947                  \n",
      "   118     0.656277   1.29589    0.561233                  \n",
      "   119     0.660223   1.301472   0.559031                  \n",
      "   120     0.658702   1.297172   0.556828                  \n",
      "   121     0.657073   1.28774    0.560793                  \n",
      "   122     0.66203    1.291555   0.555066                  \n",
      "   123     0.65216    1.287151   0.556828                  \n",
      "   124     0.652359   1.301293   0.561233                  \n",
      "   125     0.648901   1.306631   0.565198                  \n",
      "   126     0.635885   1.301607   0.562996                  \n",
      "   127     0.646287   1.292456   0.564317                  \n",
      "   128     0.652304   1.294025   0.560793                  \n",
      "   129     0.648829   1.306788   0.557709                  \n",
      "   130     0.629881   1.313728   0.554626                  \n",
      "   131     0.624116   1.306443   0.559471                  \n",
      "   132     0.619558   1.313796   0.563436                  \n",
      "   133     0.613037   1.305141   0.560793                  \n",
      "   134     0.633728   1.306494   0.556388                  \n",
      "   135     0.613413   1.294736   0.567401                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   136     0.626498   1.298369   0.557269                  \n",
      "   137     0.625337   1.307487   0.561674                  \n",
      "   138     0.606445   1.312342   0.56652                   \n",
      "   139     0.617421   1.30484    0.566079                  \n",
      "   140     0.61476    1.298562   0.564317                  \n",
      "   141     0.621951   1.305044   0.564758                  \n",
      "   142     0.620459   1.299569   0.562996                  \n",
      "   143     0.610296   1.311561   0.559471                  \n",
      "   144     0.608779   1.313595   0.565639                  \n",
      "   145     0.607396   1.315892   0.570044                  \n",
      "   146     0.602978   1.310348   0.564758                  \n",
      "   147     0.605884   1.305668   0.559031                  \n",
      "   148     0.601808   1.328027   0.561674                  \n",
      "   149     0.600352   1.328305   0.559912                  \n",
      "   150     0.605798   1.332449   0.563436                  \n",
      "   151     0.598731   1.321423   0.555507                  \n",
      "   152     0.593817   1.332482   0.562115                  \n",
      "   153     0.599667   1.319844   0.55815                   \n",
      "   154     0.589238   1.319507   0.560352                  \n",
      "   155     0.590561   1.312429   0.563436                  \n",
      "   156     0.594656   1.321561   0.569163                  \n",
      "   157     0.590181   1.318324   0.562996                  \n",
      "   158     0.589214   1.319377   0.56696                   \n",
      "   159     0.584094   1.306899   0.559912                  \n",
      "   160     0.583305   1.318105   0.560793                  \n",
      "   161     0.591204   1.336694   0.556828                  \n",
      "   162     0.572753   1.34172    0.561233                  \n",
      "   163     0.584081   1.338934   0.560793                  \n",
      "   164     0.580057   1.343101   0.562555                  \n",
      "   165     0.581571   1.353941   0.559912                  \n",
      "   166     0.569839   1.340638   0.563436                  \n",
      "   167     0.569617   1.342894   0.557269                  \n",
      "   168     0.57243    1.355735   0.561674                  \n",
      "   169     0.580024   1.338136   0.55859                   \n",
      "   170     0.578816   1.341522   0.562555                  \n",
      "   171     0.572516   1.338547   0.561233                  \n",
      "   172     0.570096   1.340649   0.559912                  \n",
      "   173     0.568945   1.340035   0.55859                   \n",
      "   174     0.56571    1.348905   0.562115                  \n",
      "   175     0.581353   1.356797   0.564317                  \n",
      "   176     0.562718   1.346432   0.561674                  \n",
      "   177     0.568406   1.355216   0.566079                  \n",
      "   178     0.567246   1.358937   0.559031                  \n",
      "   179     0.561946   1.352142   0.562115                  \n",
      "   180     0.565195   1.351317   0.562555                  \n",
      "   181     0.545607   1.359034   0.55859                   \n",
      "   182     0.550421   1.347423   0.562555                  \n",
      "   183     0.551233   1.362297   0.563877                  \n",
      "   184     0.54831    1.361329   0.562996                  \n",
      "   185     0.550532   1.356005   0.55859                   \n",
      "   186     0.549916   1.368139   0.560793                  \n",
      "   187     0.557924   1.350603   0.562115                  \n",
      "   188     0.560512   1.352816   0.566079                  \n",
      "   189     0.551746   1.359251   0.562996                  \n",
      "   190     0.541333   1.358993   0.566079                  \n",
      "   191     0.540756   1.372814   0.563436                  \n",
      "   192     0.545269   1.353797   0.561674                  \n",
      "   193     0.546848   1.361625   0.559471                  \n",
      "   194     0.542648   1.370788   0.561674                  \n",
      "   195     0.542125   1.359173   0.559912                  \n",
      "   196     0.530001   1.358159   0.559912                  \n",
      "   197     0.540171   1.361648   0.564758                  \n",
      "   198     0.551827   1.369738   0.560793                  \n",
      "   199     0.544986   1.373581   0.560793                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.37358]), 0.5607929516468805]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c70d97d62115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-2, 100, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('224_preF_b58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('224_preF_b58')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96784f7dee6249c891fdde4ff2d4f690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Starting training on small images for a few epochs, then switching to bigger images, and continuing training is an amazingly effective way to avoid overfitting.\n",
    "\n",
    "# http://forums.fast.ai/t/planet-classification-challenge/7824/96\n",
    "# set_data doesnt change the model at all. It just gives it new data to train with.\n",
    "learn.set_data(get_data(299, 80)) \n",
    "learn.freeze()\n",
    "\n",
    "#Source:   \n",
    "#    def set_data(self, data, precompute=False):\n",
    "#        super().set_data(data)\n",
    "#        if precompute:\n",
    "#            self.unfreeze()\n",
    "#            self.save_fc1()\n",
    "#            self.freeze()\n",
    "#            self.precompute = True\n",
    "#        else:\n",
    "#            self.freeze()\n",
    "#File:      ~/fastai/courses/dl1/fastai/conv_learner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 299, 299]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 9408)])),\n",
       "             ('BatchNorm2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 128)])),\n",
       "             ('ReLU-3',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('MaxPool2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-5',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 16384)])),\n",
       "             ('BatchNorm2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-7',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('BatchNorm2d-9',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-10',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-11',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 65536)])),\n",
       "             ('BatchNorm2d-12',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('Conv2d-13',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 16384)])),\n",
       "             ('BatchNorm2d-14',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-15',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-16',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 65536)])),\n",
       "             ('BatchNorm2d-17',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-18',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-19',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('BatchNorm2d-20',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-21',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-22',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 65536)])),\n",
       "             ('BatchNorm2d-23',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-24',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-25',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 65536)])),\n",
       "             ('BatchNorm2d-26',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-27',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-28',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('BatchNorm2d-29',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-30',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-31',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 65536)])),\n",
       "             ('BatchNorm2d-32',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 512)])),\n",
       "             ('ReLU-33',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 256, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-34',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 512, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 131072)])),\n",
       "             ('BatchNorm2d-35',\n",
       "              OrderedDict([('input_shape', [-1, 512, 75, 75]),\n",
       "                           ('output_shape', [-1, 512, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-36',\n",
       "              OrderedDict([('input_shape', [-1, 512, 75, 75]),\n",
       "                           ('output_shape', [-1, 512, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-37',\n",
       "              OrderedDict([('input_shape', [-1, 512, 75, 75]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('BatchNorm2d-38',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-39',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-40',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-41',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('Conv2d-42',\n",
       "              OrderedDict([('input_shape', [-1, 256, 75, 75]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 131072)])),\n",
       "             ('BatchNorm2d-43',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-44',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-45',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-46',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-47',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-48',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('BatchNorm2d-49',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-50',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-51',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-52',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-53',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-54',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-55',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-56',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-57',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('BatchNorm2d-58',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-59',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-60',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-61',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-62',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-63',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-64',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-65',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-66',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('BatchNorm2d-67',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-68',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-69',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 262144)])),\n",
       "             ('BatchNorm2d-70',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('ReLU-71',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 512, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-72',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 1024, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 524288)])),\n",
       "             ('BatchNorm2d-73',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 38, 38]),\n",
       "                           ('output_shape', [-1, 1024, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-74',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 38, 38]),\n",
       "                           ('output_shape', [-1, 1024, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-75',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 38, 38]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-76',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-77',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-78',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-79',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('Conv2d-80',\n",
       "              OrderedDict([('input_shape', [-1, 512, 38, 38]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 524288)])),\n",
       "             ('BatchNorm2d-81',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-82',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-83',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-84',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-85',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-86',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-87',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-88',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-89',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-90',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-91',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-92',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-93',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-94',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-95',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-96',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-97',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-98',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-99',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-100',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-101',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-102',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-103',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-104',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-105',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-106',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-107',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-108',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-109',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-110',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-111',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-112',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-113',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-114',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-115',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-116',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-117',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-118',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-119',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-120',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-121',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-122',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-123',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-124',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-125',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-126',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-127',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-128',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-129',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-130',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-131',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-132',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-133',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-134',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-135',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-136',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-137',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-138',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-139',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-140',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-141',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-142',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-143',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-144',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-145',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-146',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-147',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-148',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-149',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-150',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-151',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-152',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-153',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-154',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-155',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-156',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-157',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-158',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-159',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-160',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-161',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-162',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-163',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-164',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-165',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-166',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-167',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-168',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-169',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-170',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-171',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-172',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-173',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-174',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-175',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-176',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-177',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-178',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-179',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-180',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-181',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-182',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-183',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-184',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-185',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-186',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-187',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-188',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-189',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-190',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-191',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-192',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-193',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-194',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-195',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-196',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-197',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-198',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-199',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-200',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-201',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-202',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-203',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-204',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-205',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-206',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-207',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-208',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-209',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-210',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-211',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-212',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-213',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-214',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-215',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-216',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-217',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-218',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-219',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-220',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-221',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-222',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-223',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-224',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-225',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-226',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-227',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-228',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-229',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-230',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-231',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-232',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-233',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-234',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-235',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-236',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-237',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-238',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-239',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-240',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-241',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-242',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-243',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-244',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-245',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-246',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-247',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-248',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-249',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-250',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-251',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-252',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-253',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-254',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-255',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-256',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-257',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-258',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-259',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-260',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-261',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-262',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-263',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-264',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-265',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-266',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-267',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-268',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-269',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-270',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-271',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-272',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-273',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-274',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-275',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 147456)])),\n",
       "             ('BatchNorm2d-276',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-277',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-278',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 1048576)])),\n",
       "             ('BatchNorm2d-279',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2048)])),\n",
       "             ('ReLU-280',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 1024, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-281',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 2048, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2097152)])),\n",
       "             ('BatchNorm2d-282',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 19, 19]),\n",
       "                           ('output_shape', [-1, 2048, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-283',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 19, 19]),\n",
       "                           ('output_shape', [-1, 2048, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-284',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 19, 19]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 589824)])),\n",
       "             ('BatchNorm2d-285',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-286',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-287',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4194304)])),\n",
       "             ('BatchNorm2d-288',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('Conv2d-289',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 19, 19]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 2097152)])),\n",
       "             ('BatchNorm2d-290',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-291',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-292',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4194304)])),\n",
       "             ('BatchNorm2d-293',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-294',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-295',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 589824)])),\n",
       "             ('BatchNorm2d-296',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-297',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-298',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4194304)])),\n",
       "             ('BatchNorm2d-299',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-300',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-301',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4194304)])),\n",
       "             ('BatchNorm2d-302',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-303',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-304',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 589824)])),\n",
       "             ('BatchNorm2d-305',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-306',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-307',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4194304)])),\n",
       "             ('BatchNorm2d-308',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', 4096)])),\n",
       "             ('ReLU-309',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveMaxPool2d-310',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveAvgPool2d-311',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 2048, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveConcatPool2d-312',\n",
       "              OrderedDict([('input_shape', [-1, 2048, 10, 10]),\n",
       "                           ('output_shape', [-1, 4096, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Flatten-313',\n",
       "              OrderedDict([('input_shape', [-1, 4096, 1, 1]),\n",
       "                           ('output_shape', [-1, 4096]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm1d-314',\n",
       "              OrderedDict([('input_shape', [-1, 4096]),\n",
       "                           ('output_shape', [-1, 4096]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 8192)])),\n",
       "             ('Dropout-315',\n",
       "              OrderedDict([('input_shape', [-1, 4096]),\n",
       "                           ('output_shape', [-1, 4096]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-316',\n",
       "              OrderedDict([('input_shape', [-1, 4096]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2097664)])),\n",
       "             ('ReLU-317',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm1d-318',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1024)])),\n",
       "             ('Dropout-319',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-320',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 12]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 6156)])),\n",
       "             ('LogSoftmax-321',\n",
       "              OrderedDict([('input_shape', [-1, 12]),\n",
       "                           ('output_shape', [-1, 12]),\n",
       "                           ('nb_params', 0)]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c463da88530e46be93028e6fa29c03ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.626417   1.426835   0.503524  \n",
      "    1      1.595296   1.415666   0.511013                   \n",
      "    2      1.552414   1.397453   0.514097                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.39745]), 0.514096918203232]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(5e-3, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is much lower than training loss. This is a sign of underfitting. Cycle_len=1 may be too short. Let's set cycle_mult=2 to find better parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4bd11556e14dc3be65e09eda4dfb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.515581   1.383625   0.522026  \n",
      "    1      1.507568   1.370226   0.519383                   \n",
      "    2      1.471789   1.36212    0.52467                    \n",
      "    3      1.465919   1.36207    0.522026                   \n",
      "    4      1.451652   1.337367   0.533921                   \n",
      "    5      1.427047   1.333412   0.53304                    \n",
      "    6      1.415496   1.328908   0.531278                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.32891]), 0.531277537477174]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When you are under fitting, it means cycle_len=1 is too short (learning rate is getting reset before it had the chance to zoom in properly).\n",
    "learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2) # 1+2+4 = 7 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loss and validation loss are getting closer and smaller. We are on right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5330396475770925, 1.3259945803139326)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_preds, y = learn.TTA() # (5, 2044, 120), (2044,)\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270, array([9, 9, 9, 9, 9]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.val_ds.y), data.val_ds.y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('299_pre_bs80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('299_pre_bs80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91aa48489fce4863bbefd3ad30476171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.437424   1.327512   0.537445  \n",
      "    1      1.412686   1.320846   0.529956                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.32085]), 0.5299559487645321]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 1, cycle_len=2) # 1+1 = 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('299_pre_bs80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('299_pre_bs80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5259911894273128, 1.3275131736628687)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=np.array([5e-5,5e-4,5e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af18979f8d24f6d83dcac04a6ed7151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.set_data(get_data(299, 48)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668e2c7c4ca64a0d8ee3ea988160294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%| | 193/228 [01:58<00:20,  1.67it/s, loss=5.47]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf=learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0d779acb94408da8bc432d45dc97ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.448863   1.311074   0.534361  \n",
      "    1      1.405124   1.303028   0.538767                   \n",
      "    2      1.396005   1.306464   0.535683                   \n",
      "    3      1.402845   1.303234   0.547137                   \n",
      "    4      1.372364   1.297798   0.544934                   \n",
      "    5      1.342952   1.290582   0.542731                   \n",
      "    6      1.379837   1.28929    0.546696                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.28929]), 0.5466960388395755]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('299_12cls_unf_bs48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('299_12cls_unf_bs48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ecb8b5806a417dbfe25ade95d37e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.372671   1.290845   0.547577  \n",
      "    1      1.380739   1.278982   0.542291                   \n",
      "    2      1.368688   1.279418   0.546696                   \n",
      "    3      1.367094   1.272629   0.548018                   \n",
      "    4      1.345491   1.272921   0.553304                   \n",
      "    5      1.333466   1.267104   0.553744                   \n",
      "    6      1.334859   1.264128   0.553304                   \n",
      "    7      1.371418   1.269992   0.547137                   \n",
      "    8      1.364804   1.263759   0.559031                   \n",
      "    9      1.343403   1.25903    0.561674                   \n",
      "    10     1.344066   1.254189   0.557269                   \n",
      "    11     1.332897   1.248577   0.552423                   \n",
      "    12     1.28492    1.243182   0.556388                   \n",
      "    13     1.310286   1.241637   0.554185                   \n",
      "    14     1.273155   1.241403   0.554626                   \n",
      "    15     1.35625    1.242023   0.557269                   \n",
      "    16     1.328576   1.245065   0.54978                    \n",
      "    17     1.290075   1.243276   0.559471                   \n",
      "    18     1.304591   1.246133   0.560793                   \n",
      "    19     1.278822   1.233118   0.559471                   \n",
      "    20     1.281957   1.234232   0.553744                   \n",
      "    21     1.242081   1.222856   0.566079                   \n",
      "    22     1.263597   1.224243   0.561674                   \n",
      "    23     1.244797   1.217598   0.567841                   \n",
      "    24     1.232354   1.216485   0.564317                   \n",
      "    25     1.259178   1.212913   0.566079                   \n",
      "    26     1.240846   1.20705    0.565198                   \n",
      "    27     1.236394   1.207521   0.567401                   \n",
      "    28     1.234203   1.203971   0.568722                   \n",
      "    29     1.235416   1.206624   0.570925                   \n",
      "    30     1.199661   1.206389   0.563877                   \n",
      "    31     1.241285   1.206337   0.563877                   \n",
      " 99%|| 188/190 [02:18<00:01,  1.38it/s, loss=1.27]"
     ]
    }
   ],
   "source": [
    "learn.fit(lr, 10, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is so similar to ImageNet dataset. Training convolution layers doesn't help much. We are not going to unfreeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission\n",
    "\n",
    "https://youtu.be/9C06ZPF8Uuc?t=1905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA(is_test=True) # use test dataset rather than validation dataset\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "#accuracy_np(probs, y), metrcs.log_loss(y, probs) # This does not make sense since test dataset has no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape # (n_images, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(probs)\n",
    "df.columns = data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'id', [o[5:-4] for o in data.test_ds.fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}/subm/'\n",
    "os.makedirs(SUBM, exist_ok=True)\n",
    "df.to_csv(f'{SUBM}subm.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(f'{SUBM}subm.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = data.val_ds.fnames[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(PATH + fn).resize((150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "ds = FilesIndexArrayDataset([fn], np.array([0]), val_tfms, PATH)\n",
    "dl = DataLoader(ds)\n",
    "preds = learn.predict_dl(dl)\n",
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.classes[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "im = val_tfms(open_image(PATH + fn)) # open_image() returns numpy.ndarray\n",
    "preds = learn.predict_array(im[None])\n",
    "np.argmax(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastaiold",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0147ea39a83144aa99e7877a908ca502": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "02af08793c9a4c5ba0cbd7462a715f89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "03c7476e32ce48c2b38a7023c2dcc0a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "075434e4b0234c5fa61c8d63fec51679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "08ba1e10c1a641f7876680a632f6821d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b0edcf9ef0754ca4bb7fe6e8790c464b",
       "max": 6,
       "style": "IPY_MODEL_c13bdace91114d639b408aa120c97f79",
       "value": 6
      }
     },
     "0b49f5119c6d4a25bb575a20e33fe219": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12cc98b1fc954667bd49c08972278f1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "13cbbf3a554a40f09d40df39c2cacf47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "148c1abd5f1747a2a787c09cef3071bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_902c060a37b4491788462dce6be1798b",
       "style": "IPY_MODEL_88db019106ca4893816ea780e567a175",
       "value": "100% 3/3 [16:30&lt;00:00, 330.17s/it]"
      }
     },
     "16993380d0fa42b888a52dbf1bb42f20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c74dedf09f57490a9f1ac9af54e14bf3",
       "max": 6,
       "style": "IPY_MODEL_557d35c901f54575b5963e3b7ce932a3",
       "value": 6
      }
     },
     "19c5557812814cb28bc7e0cc80c65c5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1c241c0e5b5844508c1c50e2a7c09b1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1c509f99160e41d5af6e565b1541e571": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9352e3fd2af54e09ad67afb4ac446b27",
       "style": "IPY_MODEL_62e7ecfbbea7427385deb25ed2f4232f",
       "value": "100% 6/6 [00:00&lt;00:00, 380.26it/s]"
      }
     },
     "1e2f1c40607144eb9cb7b9e257d06f35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1fc90792a2b74c38aaf73659c3756831": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "201ae86e437e4b5390782e9df272326d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c8871c57d7bd4b61a99633668fb44621",
        "IPY_MODEL_38eb37d7293d4273a6ae06b5a451617d"
       ],
       "layout": "IPY_MODEL_1c241c0e5b5844508c1c50e2a7c09b1b"
      }
     },
     "20bfce64bf354e2398353b6a2a31d0e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21e75994f5e749748dd5693819e51d93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "22952b3bfa674aff898e452b30bd319e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "26e2b0e7abb24e3fad1b5c0c166aa44d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_363595af2f5f4ad3a3f5a9e46069d58e",
       "max": 5,
       "style": "IPY_MODEL_02af08793c9a4c5ba0cbd7462a715f89",
       "value": 5
      }
     },
     "288366a4c5ba435286c34d6d5ad69201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_33f7abed940a4b24b01110da8ec67ddc",
        "IPY_MODEL_93f4380114fe48b88db18d0c97736fd4"
       ],
       "layout": "IPY_MODEL_5b17418f64954c14843a914942f8ce3d"
      }
     },
     "292be092bc964dd7a48bc62c906f5814": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2d1dfcb285154a7bac2db184a87f3c4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2ff92f760a2b46a99576ab77daccac1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33ce7c9b732e4715ae12b71669addfdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_20bfce64bf354e2398353b6a2a31d0e5",
       "max": 6,
       "style": "IPY_MODEL_830aa543858f4a54a14aad440bcbde34",
       "value": 6
      }
     },
     "33f7abed940a4b24b01110da8ec67ddc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7ba0d94e2ef544fe9126eacee6588468",
       "max": 6,
       "style": "IPY_MODEL_8c8cb52ff5e54c55a297af7571a105ea",
       "value": 6
      }
     },
     "363595af2f5f4ad3a3f5a9e46069d58e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37f00a662a3c4b5f9f29db6903cfc5ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "37faed3c96f343e895d8f29ab07137c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "38eb37d7293d4273a6ae06b5a451617d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42c23fec7e814a9aaf39ffa59c0ffe20",
       "style": "IPY_MODEL_7163788d004d4c15b0b0137a654079a0",
       "value": "100% 7/7 [35:35&lt;00:00, 305.08s/it]"
      }
     },
     "39cf7d6b5e98460e9a621f1d74e32fad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cb554ddf38bb4597b282655ee74ca321",
       "style": "IPY_MODEL_c45beabad9d34af5b39ce603b5308ef9",
       "value": "100% 5/5 [27:26&lt;00:00, 329.38s/it]"
      }
     },
     "39d7df82d70b40df9f1171dad9ce2b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3a1160614abc4724b73cc9bc2e0d0d46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_19c5557812814cb28bc7e0cc80c65c5f",
       "style": "IPY_MODEL_87707de469bc4c4bb2ba2a2ed7322de1",
       "value": "100% 5/5 [00:28&lt;00:00,  5.70s/it]"
      }
     },
     "3b2e29458fdc49d0864a7fc9a1faafb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3ed035ff92d947ad9059d4bc03f2576c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_16993380d0fa42b888a52dbf1bb42f20",
        "IPY_MODEL_a52bd3eee7aa4e9093ee525fc42ff232"
       ],
       "layout": "IPY_MODEL_66e271ee790148eb89ae51b9b22216aa"
      }
     },
     "40060908ceee46fb859195274eca3da8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4b3362ffeac948e490ce91f1e0786f2e",
        "IPY_MODEL_c09f764cc1c74e3aa75fea864a8d21f3"
       ],
       "layout": "IPY_MODEL_e6926f2efb5340528a00c5045376c380"
      }
     },
     "405077ae66ac44afbd35d90a6afd6cab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "41a9d48c29ef4752bcd2ddc7076dac3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "42c23fec7e814a9aaf39ffa59c0ffe20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43f1cb9394c5422798a91c1b6b0a5907": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45a9f25bf3964af68dfce8bbb2091917": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4654ebf91a484cb8b153920fb89bb522": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b3362ffeac948e490ce91f1e0786f2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_67e1b7b183484f03b2f63c22c44e8713",
       "max": 6,
       "style": "IPY_MODEL_12cc98b1fc954667bd49c08972278f1d",
       "value": 6
      }
     },
     "4c5e108b0b9145cb9987a673dda89bb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4d7cbd1c9b0b45359d4d31ad4e50e441": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "54f04d9c381446649b742e1242de6953": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_f6539e378c294a6c955da278da4ade4e",
       "max": 2,
       "style": "IPY_MODEL_b1cddc992f864976b0f4132e0c4819f4",
       "value": 2
      }
     },
     "557d35c901f54575b5963e3b7ce932a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5791e4167111408ca3f1be2e16334803": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5b0ec0306b6440c1a068951bf0d4a50c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5b17418f64954c14843a914942f8ce3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5b494db622384a7fabd7ed86d7f0575c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_26e2b0e7abb24e3fad1b5c0c166aa44d",
        "IPY_MODEL_c05cfeeac9a04c68a7387dc65bf48227"
       ],
       "layout": "IPY_MODEL_4654ebf91a484cb8b153920fb89bb522"
      }
     },
     "5c13867f02614d49bc038af563f5a5a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7234b227a46b404598576e19a230a94e",
       "max": 6,
       "style": "IPY_MODEL_7ae2ea4a6e144242ad504c2032fbb9b9",
       "value": 6
      }
     },
     "5d3aa8de854a491485458bcaf88b9de4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c6a3a9d502b94ffba6cb6708c9762bd0",
        "IPY_MODEL_8d9389e09e1d44d88ffffdb83ac6f407"
       ],
       "layout": "IPY_MODEL_03c7476e32ce48c2b38a7023c2dcc0a1"
      }
     },
     "5f4033806f5144f28e0999110bf34612": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_e59a2233ae454d81ada1b8494763e7bc",
       "max": 2,
       "style": "IPY_MODEL_292be092bc964dd7a48bc62c906f5814",
       "value": 2
      }
     },
     "61defccfe9dc4330931ce420b9976dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4d7cbd1c9b0b45359d4d31ad4e50e441",
       "style": "IPY_MODEL_45a9f25bf3964af68dfce8bbb2091917",
       "value": "100% 2/2 [10:08&lt;00:00, 304.26s/it]"
      }
     },
     "62e7ecfbbea7427385deb25ed2f4232f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "62e8fbf1622b4a36a186e7f319552990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_41a9d48c29ef4752bcd2ddc7076dac3c",
       "max": 2,
       "style": "IPY_MODEL_5b0ec0306b6440c1a068951bf0d4a50c",
       "value": 2
      }
     },
     "65d9210f3d3345019a1fcf4ad82f1ae9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "66179fdeb4534eb281f2690ded33950e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "66e271ee790148eb89ae51b9b22216aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67e1b7b183484f03b2f63c22c44e8713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7163788d004d4c15b0b0137a654079a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7234b227a46b404598576e19a230a94e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "77132b06e4ad40fdabdc0dd93922af21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "784cd320488247aa87d575558f81d06b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7998921f656343ffadf133220692f859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_0b49f5119c6d4a25bb575a20e33fe219",
       "max": 5,
       "style": "IPY_MODEL_cfeaf84bdbe34c7898e1ea8fc61b539c",
       "value": 5
      }
     },
     "7ad08fc0082a41bc882cedf6004206dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_33ce7c9b732e4715ae12b71669addfdf",
        "IPY_MODEL_bc6e6b33b84344f094704454a0cf6f6b"
       ],
       "layout": "IPY_MODEL_2ff92f760a2b46a99576ab77daccac1d"
      }
     },
     "7adf432cd98f46df927bf9da9d94b182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7ae2ea4a6e144242ad504c2032fbb9b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7b215de0d6b64c3897c22bd817bbcb8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_1e2f1c40607144eb9cb7b9e257d06f35",
       "max": 3,
       "style": "IPY_MODEL_f38f8ae81eca43f9b1828369ebffd849",
       "value": 3
      }
     },
     "7ba0d94e2ef544fe9126eacee6588468": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8228413e70844312b5aa3128e3bea3ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_890f789420e4416697cafbf732f38b95",
       "style": "IPY_MODEL_b52cba9c0daf49aab716b75c91137766",
       "value": "100% 2/2 [00:06&lt;00:00,  3.12s/it]"
      }
     },
     "830aa543858f4a54a14aad440bcbde34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "868f105f38aa47b2b0223680dc202859": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "87707de469bc4c4bb2ba2a2ed7322de1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "879f0f26c06041698336e79b9b92b0c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c19f1e5cf61444b5926c89b67c374dc8",
        "IPY_MODEL_148c1abd5f1747a2a787c09cef3071bc"
       ],
       "layout": "IPY_MODEL_b4a9636246544cd7a3ebcff56595bea2"
      }
     },
     "88db019106ca4893816ea780e567a175": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "890f789420e4416697cafbf732f38b95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c8cb52ff5e54c55a297af7571a105ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8d9389e09e1d44d88ffffdb83ac6f407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1fc90792a2b74c38aaf73659c3756831",
       "style": "IPY_MODEL_66179fdeb4534eb281f2690ded33950e",
       "value": "100% 2/2 [00:06&lt;00:00,  3.17s/it]"
      }
     },
     "902c060a37b4491788462dce6be1798b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91b150ff417c44d1bc68e66d1b3c5925": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9352e3fd2af54e09ad67afb4ac446b27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "93f4380114fe48b88db18d0c97736fd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b7e6303bb38542c9a8282079c33beca7",
       "style": "IPY_MODEL_21e75994f5e749748dd5693819e51d93",
       "value": "100% 6/6 [00:00&lt;00:00, 343.35it/s]"
      }
     },
     "956dbbddf33a476db031c3d1b8ad5b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7998921f656343ffadf133220692f859",
        "IPY_MODEL_39cf7d6b5e98460e9a621f1d74e32fad"
       ],
       "layout": "IPY_MODEL_65d9210f3d3345019a1fcf4ad82f1ae9"
      }
     },
     "a19c0f9c5cb34e9e8cdfe5c356084b80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a52bd3eee7aa4e9093ee525fc42ff232": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_405077ae66ac44afbd35d90a6afd6cab",
       "style": "IPY_MODEL_fa7fbd7aa5ab41a5aaabfca1db46058e",
       "value": "100% 6/6 [00:00&lt;00:00, 377.47it/s]"
      }
     },
     "a6ba13af33984f1b96ed120d3798b035": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a6cf535c8f30471e947503cae6bdb611": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_e77a75b0e9b446318ef399e225003e65",
       "max": 7,
       "style": "IPY_MODEL_c8469a077e5449b69821e6b27b8e74e5",
       "value": 7
      }
     },
     "a7afeac8de60479e8c92248312fde8fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aad1581c410d48feb48e6b943c14bdb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b0edcf9ef0754ca4bb7fe6e8790c464b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b1258a718296423d9f4d9c0535aae63b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3b2e29458fdc49d0864a7fc9a1faafb6",
       "style": "IPY_MODEL_37f00a662a3c4b5f9f29db6903cfc5ba",
       "value": "100% 3/3 [15:16&lt;00:00, 305.39s/it]"
      }
     },
     "b1cddc992f864976b0f4132e0c4819f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b3ae58ce0bce4cd1b678a043b8ce4415": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_54f04d9c381446649b742e1242de6953",
        "IPY_MODEL_e10c6be126a045d9809b90c0880e7362"
       ],
       "layout": "IPY_MODEL_77132b06e4ad40fdabdc0dd93922af21"
      }
     },
     "b4a9636246544cd7a3ebcff56595bea2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b4c9fe6ac6f649dc9ed8a077a5eaeb20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b52cba9c0daf49aab716b75c91137766": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b7e6303bb38542c9a8282079c33beca7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ba26964d72134b3aa6095e3102f1531b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc6e6b33b84344f094704454a0cf6f6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e6337586212341de8a4de0ce6bd25649",
       "style": "IPY_MODEL_7adf432cd98f46df927bf9da9d94b182",
       "value": "100% 6/6 [00:00&lt;00:00, 270.73it/s]"
      }
     },
     "bd8469f87f2d4e789610110acd07571d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ed2e720acb7a467c85bd7db465281523",
        "IPY_MODEL_3a1160614abc4724b73cc9bc2e0d0d46"
       ],
       "layout": "IPY_MODEL_37faed3c96f343e895d8f29ab07137c0"
      }
     },
     "c01a6ed0806a4aaaaf580bf56e78398f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c05cfeeac9a04c68a7387dc65bf48227": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a7afeac8de60479e8c92248312fde8fc",
       "style": "IPY_MODEL_22952b3bfa674aff898e452b30bd319e",
       "value": "100% 5/5 [00:16&lt;00:00,  3.28s/it]"
      }
     },
     "c09f764cc1c74e3aa75fea864a8d21f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c80d11f161704ab3bda86e7d1dfaff03",
       "style": "IPY_MODEL_e1df5ccb47594688afaee7c51d9cfeed",
       "value": "100% 6/6 [00:00&lt;00:00, 377.26it/s]"
      }
     },
     "c13bdace91114d639b408aa120c97f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c19f1e5cf61444b5926c89b67c374dc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_43f1cb9394c5422798a91c1b6b0a5907",
       "max": 3,
       "style": "IPY_MODEL_aad1581c410d48feb48e6b943c14bdb8",
       "value": 3
      }
     },
     "c28408357da544cd8c8bbd5c7469e541": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5c13867f02614d49bc038af563f5a5a2",
        "IPY_MODEL_1c509f99160e41d5af6e565b1541e571"
       ],
       "layout": "IPY_MODEL_e41e9dc77ce44f3fad0aee4db429cd7d"
      }
     },
     "c30905e882964682bbe231e445b57833": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_08ba1e10c1a641f7876680a632f6821d",
        "IPY_MODEL_e6f6231f671e4871b9e496cce50bf2b9"
       ],
       "layout": "IPY_MODEL_db256ef0046f46d085353ffba880c8fa"
      }
     },
     "c438be876cfc49e8920f2704c6cddbdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_de9c288444e74ea38dbac2ef1b1078e4",
        "IPY_MODEL_fe3c562acb4e432280f6432df0710577"
       ],
       "layout": "IPY_MODEL_ba26964d72134b3aa6095e3102f1531b"
      }
     },
     "c45beabad9d34af5b39ce603b5308ef9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c522ca216e5a49e4a7624f94b7215c52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_62e8fbf1622b4a36a186e7f319552990",
        "IPY_MODEL_8228413e70844312b5aa3128e3bea3ad"
       ],
       "layout": "IPY_MODEL_cb6af7a441964132bb58e75ef7b4bd19"
      }
     },
     "c6a3a9d502b94ffba6cb6708c9762bd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_868f105f38aa47b2b0223680dc202859",
       "max": 2,
       "style": "IPY_MODEL_f4c78df23c774bb290250936916d962e",
       "value": 2
      }
     },
     "c74dedf09f57490a9f1ac9af54e14bf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c80d11f161704ab3bda86e7d1dfaff03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8469a077e5449b69821e6b27b8e74e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c8871c57d7bd4b61a99633668fb44621": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_2d1dfcb285154a7bac2db184a87f3c4e",
       "max": 7,
       "style": "IPY_MODEL_ce4922cb72aa4e5c8b5713e47e49029e",
       "value": 7
      }
     },
     "c8ef187b9a1249018de7378cee824894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7b215de0d6b64c3897c22bd817bbcb8d",
        "IPY_MODEL_b1258a718296423d9f4d9c0535aae63b"
       ],
       "layout": "IPY_MODEL_784cd320488247aa87d575558f81d06b"
      }
     },
     "cac9427c464f4db9b71c36da9245c066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cb554ddf38bb4597b282655ee74ca321": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cb6af7a441964132bb58e75ef7b4bd19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce4922cb72aa4e5c8b5713e47e49029e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cfeaf84bdbe34c7898e1ea8fc61b539c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d2b4db8ba2cb4c859ba3e0041c243193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_13cbbf3a554a40f09d40df39c2cacf47",
       "style": "IPY_MODEL_91b150ff417c44d1bc68e66d1b3c5925",
       "value": "100% 7/7 [38:27&lt;00:00, 329.65s/it]"
      }
     },
     "db256ef0046f46d085353ffba880c8fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "de9c288444e74ea38dbac2ef1b1078e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_0147ea39a83144aa99e7877a908ca502",
       "max": 5,
       "style": "IPY_MODEL_075434e4b0234c5fa61c8d63fec51679",
       "value": 5
      }
     },
     "def3b0d0275c454e95c5c2952fc9d017": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5f4033806f5144f28e0999110bf34612",
        "IPY_MODEL_61defccfe9dc4330931ce420b9976dcd"
       ],
       "layout": "IPY_MODEL_e22e48eeda32478cbb6bf53babd9e700"
      }
     },
     "e10c6be126a045d9809b90c0880e7362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5791e4167111408ca3f1be2e16334803",
       "style": "IPY_MODEL_c01a6ed0806a4aaaaf580bf56e78398f",
       "value": "100% 2/2 [10:59&lt;00:00, 329.53s/it]"
      }
     },
     "e1df5ccb47594688afaee7c51d9cfeed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e22e48eeda32478cbb6bf53babd9e700": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e41e9dc77ce44f3fad0aee4db429cd7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e59a2233ae454d81ada1b8494763e7bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6337586212341de8a4de0ce6bd25649": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6926f2efb5340528a00c5045376c380": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6f6231f671e4871b9e496cce50bf2b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4c5e108b0b9145cb9987a673dda89bb6",
       "style": "IPY_MODEL_a19c0f9c5cb34e9e8cdfe5c356084b80",
       "value": "100% 6/6 [00:00&lt;00:00, 42.32it/s]"
      }
     },
     "e77a75b0e9b446318ef399e225003e65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ed2e720acb7a467c85bd7db465281523": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Epoch",
       "layout": "IPY_MODEL_f9852feeb51543e4a0d21c5cd6326380",
       "max": 5,
       "style": "IPY_MODEL_cac9427c464f4db9b71c36da9245c066",
       "value": 5
      }
     },
     "f2cf6963cc204b18921e63e1933ad18b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a6cf535c8f30471e947503cae6bdb611",
        "IPY_MODEL_d2b4db8ba2cb4c859ba3e0041c243193"
       ],
       "layout": "IPY_MODEL_b4c9fe6ac6f649dc9ed8a077a5eaeb20"
      }
     },
     "f38f8ae81eca43f9b1828369ebffd849": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f4c78df23c774bb290250936916d962e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f6539e378c294a6c955da278da4ade4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f9852feeb51543e4a0d21c5cd6326380": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa7fbd7aa5ab41a5aaabfca1db46058e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fe3c562acb4e432280f6432df0710577": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.1.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a6ba13af33984f1b96ed120d3798b035",
       "style": "IPY_MODEL_39d7df82d70b40df9f1171dad9ce2b4c",
       "value": "100% 5/5 [25:26&lt;00:00, 305.38s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
